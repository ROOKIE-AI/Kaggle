{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"},{"sourceId":6837206,"sourceType":"datasetVersion","datasetId":3928299}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 🕒Time Series Course: A Practical Guide😎","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://user-images.githubusercontent.com/115424463/277927582-105276ff-72a9-439d-b80e-e44a33ba5c5d.jpg\" alt=\"'Time Series in Dali style' by AI\">\n\n### Picture: Time Series in Dali style","metadata":{"_uuid":"afb2d136-1f38-4302-bcde-29dc09c7f307","_cell_guid":"8bf0939b-cc3f-4f3e-8fbe-8c333f86458d","trusted":true}},{"cell_type":"markdown","source":"**Hello, fellow 'getting started' data fan 🤓!** \n\nJust like you, I've been steadily advancing through the micro-courses, one by one, until I reached [**Time Series**](https://www.kaggle.com/learn/time-series). While it offers a wealth of essential theory, its 'micro' nature apperently restricts the capacity for practical demostractions. Therefore, I thought there might be public interest for a practical guide.\n\nWhat you **Will Find** in the project:\n- All Time Series analysis methods covered in the course. I introduce them one by one with visualizations, code comments, and pipelines that take you from raw data to submission.csv. for [*Store Sales - Time Series Forecasting*](https://www.kaggle.com/competitions/store-sales-time-series-forecasting) competion.\n\n- Interactive visualizations. You can select a product, a store, and dates in the `Data display parameters` to make all plots adjust to your choices.  To utilize this feature, you should 'fork' (copy) the notebook and run the relevant sections.\n\n- **10 serialized models**. When you fork the notebook, you won't need to train them anew. Simply apply the pre-trained models for predictions and visualization according to your preferences.\n\n- All the utilities from the course (Periodogram, Autocorrelation, Widgets, etc). I've organized them conveniently by section so you can easily copy and take them away.\n\n- Some reflections on theoretical issues. It would be great to discuss them in comments. \n\nWhat You **Won't Find** in This Notebook:\n- Any groundbreaking decisions on achieving a high score (come on, it's 'getting started'). \n- Libraries and data are within the scope of the course.\n- I also regret passing a high score CSV through the code in one of the versions. At the time, it seemed like an innocent promotional idea, and I only read [Kaggle Community Guidlines](https://www.kaggle.com/community-guidelines) after doing that. So, it's also part of the 'getting started' process: I've learned some good manners. \n\n*Enjoy the ride!* <br>\n<blockquote style=\"margin-right:auto; margin-left:auto; background-color: #faf0be; padding: 1em; margin:24px;\">\n<strong> Please upvote if you find this valuable, and don't hesitate to leave comments if you have any feedback or suggestions </strong> <br> \n    </blockquote>","metadata":{"_uuid":"731fe5ed-7f0e-441a-9f8f-d9b1a8a3c08c","_cell_guid":"a4ab9900-deb4-427d-9678-d0d7bc566205","trusted":true}},{"cell_type":"markdown","source":"# SETTINGS","metadata":{"_uuid":"27b8d38e-fbe4-461e-8a4f-85aa4b864855","_cell_guid":"192c2cac-ecd4-4a66-856d-31482925a53d","tags":[],"trusted":true}},{"cell_type":"markdown","source":" ## imports","metadata":{"_uuid":"dbddccb4-6148-4375-8e51-80b46f4ead5e","_cell_guid":"6d0d52de-3552-470e-bef0-34bf87960ded","trusted":true}},{"cell_type":"code","source":"%%capture\n!pip install pandas==1.4.2","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:47:16.396725Z","iopub.execute_input":"2023-12-19T19:47:16.397733Z","iopub.status.idle":"2023-12-19T19:47:43.34285Z","shell.execute_reply.started":"2023-12-19T19:47:16.397694Z","shell.execute_reply":"2023-12-19T19:47:43.341454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport joblib\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.model_selection import train_test_split\n\nfrom xgboost import XGBRegressor\n\nfrom warnings import simplefilter\nsimplefilter(\"ignore\")","metadata":{"_uuid":"0023298d-20a1-4301-8193-27be4d07a899","_cell_guid":"4e9aff0b-c5d7-4990-939d-48388bcda799","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:43.344708Z","iopub.execute_input":"2023-12-19T19:47:43.345332Z","iopub.status.idle":"2023-12-19T19:47:44.828031Z","shell.execute_reply.started":"2023-12-19T19:47:43.34528Z","shell.execute_reply":"2023-12-19T19:47:44.826574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## load data\n- **train.csv** The training data, comprising time series of features store_nbr, family, and onpromotion as well as the target sales.\n- *store_nbr* identifies the store at which the products are sold.\n- *family* identifies the type of product sold.\n- *sales* gives the total sales for a product family at a particular store at a given date. Fractional values are possible since products can be sold in fractional units (1.5 kg of cheese, for instance, as opposed to 1 bag of chips). \n- *onpromotion* gives the total number of items in a product family that were being promoted at a store at a given date.\n\n\n- **test.csv**  The test data, having the same features as the training data. You will predict the target sales for the dates in this file. The dates in the test data are for the 15 days after the last date in the training data.\n\n- **holidays_events.csv**  Holidays and Events, with metadata. NOTE: Pay special attention to the `transferred` column. A holiday that is transferred officially falls on that calendar day, but was moved to another date by the government. A transferred day is more like a normal day than a holiday. To find the day that it was actually celebrated, look for the corresponding row where type is Transfer. For example, the holiday Independencia de Guayaquil was transferred from 2012-10-09 to 2012-10-12, which means it was celebrated on 2012-10-12. Days that are type Bridge are extra days that are added to a holiday (e.g., to extend the break across a long weekend). These are frequently made up by the type Work Day which is a day not normally scheduled for work (e.g., Saturday) that is meant to payback the Bridge. Additional holidays are days added a regular calendar holiday, for example, as typically happens around Christmas (making Christmas Eve a holiday).\n\n- **Additional Notes**  Wages in the public sector are paid `every two weeks` on the 15 th and on the last day of the month. Supermarket sales could be affected by this. A magnitude `7.8 earthquake` struck Ecuador on April 16, 2016. People rallied in relief efforts donating water and other first need products which greatly affected supermarket sales for several weeks after the earthquake.","metadata":{"_uuid":"6feb6e20-9f54-4196-8506-6e0a4ebe16f7","_cell_guid":"12b4ef21-7545-4a4e-8144-543ca47e12eb","trusted":true}},{"cell_type":"code","source":"comp_dir = Path('../input/store-sales-time-series-forecasting')\n\ntrain = pd.read_csv(comp_dir / 'train.csv',                            \n    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n        'onpromotion': 'uint32'\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\ntrain['date'] = train.date.dt.to_period('D')\n\ntrain = (train\n       .set_index(['date', 'family', 'store_nbr'])         # Setting MultiIndex to make unique identifiers for each 'sales' item\n       .sort_index()\n      )","metadata":{"_uuid":"b624d618-3f00-4c48-bfa2-d1063cd3380d","_cell_guid":"1e70f813-41fd-4afb-9e5a-2dadccf8e4b0","execution":{"iopub.status.busy":"2023-12-19T19:47:44.831064Z","iopub.execute_input":"2023-12-19T19:47:44.831709Z","iopub.status.idle":"2023-12-19T19:47:50.704875Z","shell.execute_reply.started":"2023-12-19T19:47:44.831669Z","shell.execute_reply":"2023-12-19T19:47:50.703432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(comp_dir/'test.csv',\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\ntest['date'] = test.date.dt.to_period('D')\ntest = test.set_index(['date', 'family', 'store_nbr']).sort_index()","metadata":{"_uuid":"f3dfbae2-4b7a-4e57-96e8-049aeb6921b7","_cell_guid":"b78f228f-74a7-4673-bbe7-d077f6236e79","execution":{"iopub.status.busy":"2023-12-19T19:47:50.707042Z","iopub.execute_input":"2023-12-19T19:47:50.707579Z","iopub.status.idle":"2023-12-19T19:47:50.778173Z","shell.execute_reply.started":"2023-12-19T19:47:50.70752Z","shell.execute_reply":"2023-12-19T19:47:50.776582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"holidays_events = pd.read_csv(\n    comp_dir/ \"holidays_events.csv\",\n    dtype={\n        'type': 'category',\n        'locale': 'category',\n        'locale_name': 'category',\n        'description': 'category',\n        'transferred': 'bool',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nholidays_events = holidays_events.set_index('date').to_period('D')","metadata":{"_uuid":"59c50aa4-279a-44b6-b2c8-1ae7aacf3599","_cell_guid":"945210b2-7ffd-4dce-b58b-35d73690948b","execution":{"iopub.status.busy":"2023-12-19T19:47:50.780018Z","iopub.execute_input":"2023-12-19T19:47:50.780478Z","iopub.status.idle":"2023-12-19T19:47:50.802118Z","shell.execute_reply.started":"2023-12-19T19:47:50.78044Z","shell.execute_reply":"2023-12-19T19:47:50.800641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualization Settings","metadata":{"_uuid":"4496ce2a-b2cb-465a-9e57-a348cd5d4682","_cell_guid":"fde099de-d7ec-40e8-b787-ec51bdfdd9db","tags":[],"trusted":true}},{"cell_type":"code","source":"# matplotlib defaults\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\n    \"figure\",\n    autolayout=True,\n    figsize=(11, 4),\n    titlesize=18,\n    titleweight='bold',\n)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=16,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"#556B2F\",          \n    style=\".-\",               \n    markeredgecolor=\"#4169E1\", \n    markerfacecolor=\"#8B0000\", \n    legend=False              \n)\n\n%config InlineBackend.figure_format = 'retina'","metadata":{"_uuid":"6e5dd5b0-7c5a-4745-a93b-4163dd434286","_cell_guid":"15010372-1355-401d-b43b-b7dc228dc433","execution":{"iopub.status.busy":"2023-12-19T19:47:50.804065Z","iopub.execute_input":"2023-12-19T19:47:50.804624Z","iopub.status.idle":"2023-12-19T19:47:51.215909Z","shell.execute_reply.started":"2023-12-19T19:47:50.80456Z","shell.execute_reply":"2023-12-19T19:47:51.214175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data display parameters\n\n<blockquote style=\"margin-right:auto; margin-left:auto; background-color: #faf0be; padding: 1em; margin:0px;\">\n<strong> Here is where you can pick what the rest of the notebook will be showing you </strong></blockquote>","metadata":{"_uuid":"b529be2e-6da7-4597-b873-e7c18c6e9c0c","_cell_guid":"6838943d-db36-44de-a836-43bebd3f9680","trusted":true}},{"cell_type":"code","source":"STORE  = '1'\nFAMILY = 'BREAD/BAKERY'\nSTART = '2016-01-01'\nEND = '2016-06-15'\n\nprint (\n    f'Number of stores:\\033[1m{train.index.get_level_values(\"store_nbr\").nunique()}\\033[0m \\n\\n'\n    f'Time range in the training set: from \\033[1m{train.index.get_level_values(\"date\")[0]}\\033[0m till \\033[1m{train.index.get_level_values(\"date\")[-1]}\\033[0m \\n\\n'\n    f'FAMILY options:{train.index.get_level_values(\"family\").unique().astype(\"str\")}'\n)","metadata":{"_uuid":"14f62f99-1018-43a7-897e-80882478a1f5","_cell_guid":"bc5678aa-4283-417b-a155-184052e9c786","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:51.217909Z","iopub.execute_input":"2023-12-19T19:47:51.218346Z","iopub.status.idle":"2023-12-19T19:47:51.364091Z","shell.execute_reply.started":"2023-12-19T19:47:51.218288Z","shell.execute_reply":"2023-12-19T19:47:51.362704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# main function for visualization\ndef check (X, \n           y = train,\n           START = START, \n           END = END,\n           FAMILY = FAMILY,\n           STORE = None,\n           Prefix = None,\n           model = None,\n           FIT = True):\n    \n    if y is train:\n        y =  (train\n              .groupby(['family', 'date'])                  # it calculates an averaged value across all the stores\n              .mean()                                       # merely for the sake of simplicity \n              .query ('family == @FAMILY')                    \n              .reset_index(level = 'family')\n              .rename(columns={'sales':'ground_truth_average'})\n              .loc [START:END, 'ground_truth_average']\n              )\n    else:\n        y = (y\n             .stack([0,1])\n             .to_frame()\n             .query('family == @FAMILY and store_nbr == @STORE')\n             .reset_index(['family', 'store_nbr'],drop=True)\n             .rename(columns={0:'ground_truth'})\n             .loc[START:END]\n             .squeeze()\n            )\n   \n    if STORE:\n        X = (X\n             .query('family == @FAMILY and store_nbr == @STORE')\n             .reset_index(['family', 'store_nbr'],drop=True)\n           )\n       \n    X_check = X.loc[START:END,:]\n    \n    if model:\n        model_ = model    \n    else:\n        model_ = LinearRegression (fit_intercept=False)\n        \n    if FIT:\n        model_.fit(X_check, y)\n        y_fit = pd.Series(model_.predict(X_check), index=X_check.index, name = 'y_fit').clip(0.0)\n    else:\n        y_fit =  X_check.squeeze()\n            \n    rmsle_train = mean_squared_log_error(y, y_fit) ** 0.5\n\n    print(f'Mean Squared Log Error: \\033[1m{rmsle_train:.5f}\\033[0m')\n        \n    ax = y.plot(**plot_params, alpha=0.5)\n    y_fit.plot(ax=ax, color=\"#4B0082\")\n    \n    if Prefix:\n        ax.set_title (f'{Prefix} for {FAMILY} at store {STORE} from {START} till {END}')\n    else:\n        ax.set_title (f'Average sales of {FAMILY} from {START} till {END}')\n    ax.legend();","metadata":{"_uuid":"8cba0221-913c-4c16-bb0d-0f032cfc5a75","_cell_guid":"d6f8dc89-b0ab-4128-8aec-e2587b847fb1","execution":{"iopub.status.busy":"2023-12-19T19:47:51.369525Z","iopub.execute_input":"2023-12-19T19:47:51.370247Z","iopub.status.idle":"2023-12-19T19:47:51.387385Z","shell.execute_reply.started":"2023-12-19T19:47:51.370187Z","shell.execute_reply":"2023-12-19T19:47:51.385176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data sets for training and visualization","metadata":{"_uuid":"fb884474-06c9-4657-b535-4f9f8029b462","_cell_guid":"b05d37e6-fb17-4389-925c-e6b11c658f33","trusted":true}},{"cell_type":"code","source":"X_train = train.copy()\n\ny_train = (X_train\n           .unstack(['family', 'store_nbr'])\n           .loc[:,\"sales\"]\n          )\n\n# Simple index with dates\nindex_ = X_train.index.get_level_values('date').unique() \n\n\n# Ground truth Series for the filtered data \ny_true = (y_train\n         .stack(['family', 'store_nbr'])\n         .to_frame()\n         .query('family == @FAMILY and store_nbr == @STORE')\n         .reset_index(['family', 'store_nbr'],drop=True)\n         .rename(columns={0:'ground_truth'})\n         .loc[START:END,:]\n         .squeeze()\n                )","metadata":{"_uuid":"28e513b9-3f09-4575-b45f-b506e0ac5536","_cell_guid":"fef7f56c-6a0a-4999-9987-96a97a8d2dc0","execution":{"iopub.status.busy":"2023-12-19T19:47:51.39016Z","iopub.execute_input":"2023-12-19T19:47:51.390721Z","iopub.status.idle":"2023-12-19T19:47:52.683758Z","shell.execute_reply.started":"2023-12-19T19:47:51.390684Z","shell.execute_reply":"2023-12-19T19:47:52.68269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *A theoretical issue*: **MultiIndex**\nI believe this is the starting point of practical application of the theory.\n\nIn time series, we analyze temporal dependencies. We compare the state of the Target variable with itself at a different point in time. This implies a couple of things:\n\n- Each unit of the target should be a time-indexed series containing a slice of information about the state of all objects at that moment. Thus, in each column, we will have a time-varying value of the same object. In other words, frozen pizza and bicycles will be in separate (independent) columns, and each of these columns will contain a time series of changes in the studied parameter (price, units sold, etc.).\n\n- To ensure that pizza stays with pizza and bikes with bikes, the data needs to be grouped by all categorical features in the dataset and spread out into a 'wide' series. Then this series is taken at each new moment, and the DataFrame is configured line by line. This is our `y`\n\nThis is where a MultiIndex comes in handy.\n\n1. You add all your categorical features to the index and make it a MultiIndex:  \n`.set_index(['date', 'family', 'store_nbr']`. <br>\n*Now, your index has 3 columns, and your TARGET is 1 value per row.*\n\n2. You pivot all index levels but 'date' from columns (long format) to rows (wide format). Note that it's still the same MultiIndex!\n`unstack(['family', 'store_nbr'])` <br>\n*Now, your index has 1 column 'date' and 2 rows and your TARGET is **1782** values per row* \n\nWhy is this helpful? Because now we have a standard **'dates'** column, just like any other time series. <br>\nWhen you query `.loc['2017-01-01']`, you obtain an array of 1782 values, the result of 54 commodity families being sold in 33 stores, each uniquely indexed.\n\nAnd what's in the columns? Precisely! Time-dependent changes for each of the 1782 values.<br> \nSo, the Linear Regression model interprets 1782 separate vectors, which essentially means that we have 1782 different Linear Regression models in one.","metadata":{"_uuid":"dde69e6d-17b7-414e-9260-017ef6e33de6","_cell_guid":"ab75ee27-3c46-4c41-a3bd-215d7ce4145c","trusted":true}},{"cell_type":"markdown","source":"# BASELINE SUBMISSION (TREND)\n- Public Score (RMSLE): **0.59435**","metadata":{"_uuid":"02aca099-0765-4ea8-8ab6-c7d8e3fa10df","_cell_guid":"c165269c-2781-46b7-8d86-972d39ba5a35","trusted":true}},{"cell_type":"code","source":"\"\"\"\nWe initiate X_time matrix with 2 columns: \n- the \"1\" for the regression to count the y-intercept when ajusting weight for this \"1\"\n- a time-dummy to work for detrending\n\"\"\"\n\nfrom statsmodels.tsa.deterministic import DeterministicProcess\n\ndp = DeterministicProcess(\n    index = index_,\n    constant = True,                # for y-intercept\n    order = 1,                      # time-dummy (to capture the trend)\n    drop = True,                  \n)\n\nX_time = dp.in_sample()             # 'in_sample' means along the given index (the dates in our training set)\n\n#Check\nX_time.shape, X_time.isna().sum().sum()","metadata":{"_uuid":"54d1f53a-cfed-4ad5-9d63-d4980899f761","_cell_guid":"cbb173a8-e6d5-45a5-b511-d0ec45d4e6e7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:52.685661Z","iopub.execute_input":"2023-12-19T19:47:52.686426Z","iopub.status.idle":"2023-12-19T19:47:52.805106Z","shell.execute_reply.started":"2023-12-19T19:47:52.686386Z","shell.execute_reply":"2023-12-19T19:47:52.803706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nVisualizing fitted curves against average sales (rather than per-family AND per-store) \nin this section is mainly to save trouble replicating the time_dummy across the MultiIndex levels.\n\"\"\"\ncheck(X_time)","metadata":{"_uuid":"28be5409-8dd3-4c14-9589-4f5c1d2ff81e","_cell_guid":"8e24cc98-faff-405d-856f-67a450d50d53","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:52.806863Z","iopub.execute_input":"2023-12-19T19:47:52.807358Z","iopub.status.idle":"2023-12-19T19:47:54.186994Z","shell.execute_reply.started":"2023-12-19T19:47:52.807294Z","shell.execute_reply":"2023-12-19T19:47:54.185628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ny_train has a 'wide' format and the model learns to predict not just 1 value, but 1782 at once.\n\"\"\"\n# base_model = LinearRegression (fit_intercept = False).fit(X_time, y_train)\n# joblib.dump(base_model, 'baseline_model.pkl')","metadata":{"_uuid":"342946f7-3e15-4739-b020-c927ff734cd7","_cell_guid":"3e1ac12e-6139-4ada-bdda-eaac4cbc5218","execution":{"iopub.status.busy":"2023-12-19T19:47:54.188524Z","iopub.execute_input":"2023-12-19T19:47:54.188882Z","iopub.status.idle":"2023-12-19T19:47:54.198959Z","shell.execute_reply.started":"2023-12-19T19:47:54.188851Z","shell.execute_reply":"2023-12-19T19:47:54.197702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create features for test set\nX_time_test = dp.out_of_sample(steps=16)    # 'out_of_sample (16)' means along the next 16 time-index labels ('days' in our case)\nX_time_test.index.name = 'date'","metadata":{"_uuid":"1a39c033-9971-428a-8b6c-5f42bd4854b5","_cell_guid":"70ebc30a-ba37-458e-bf71-d16fc6faa250","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:54.200666Z","iopub.execute_input":"2023-12-19T19:47:54.201109Z","iopub.status.idle":"2023-12-19T19:47:54.217952Z","shell.execute_reply.started":"2023-12-19T19:47:54.201063Z","shell.execute_reply":"2023-12-19T19:47:54.216509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = joblib.load('/kaggle/input/timeseriescourse-models/baseline_model.pkl')\ny_submit = pd.DataFrame(base_model.predict(X_time_test),               \n                        index = X_time_test.index,      \n                        columns = y_train.columns).clip(0.0)","metadata":{"_uuid":"2ade62a0-e463-4884-8cd5-8c540741e380","_cell_guid":"651e553c-cba2-475b-ae1c-fd3786cdef2a","collapsed":false,"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:54.219856Z","iopub.execute_input":"2023-12-19T19:47:54.220353Z","iopub.status.idle":"2023-12-19T19:47:54.248857Z","shell.execute_reply.started":"2023-12-19T19:47:54.220287Z","shell.execute_reply":"2023-12-19T19:47:54.247421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_0 = (y_submit\n            .stack(['family', 'store_nbr'])\n            .to_frame()\n            .join(test.id)\n            .rename(columns = {0:'sales'})\n            .reset_index(drop=True)\n            .reindex(columns = ['id','sales'])\n            )\n# submission_0.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"_uuid":"565e8ed4-f398-4956-ae2a-5cc7928ae286","_cell_guid":"ae4da481-5bfb-4770-a938-2773b619fc60","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:54.250539Z","iopub.execute_input":"2023-12-19T19:47:54.251632Z","iopub.status.idle":"2023-12-19T19:47:54.291601Z","shell.execute_reply.started":"2023-12-19T19:47:54.251589Z","shell.execute_reply":"2023-12-19T19:47:54.290354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *A theoretical issue*: **Polynomial Order**\n**DeterministicProcess** serves as a useful tool for employing Linear Regression with a polynomial order, \nallowing you to introduce curvature to the linear curve.<br>\nBut the truth is that the curve with any order, greater than 1 *FREAKS OUT* beyond the training sample.<br>\nThink of this: when you 'fit' a LinReg, you adjust weights to the terms of your polynomial and keep them 'in a leash'.<br> \nBut when you 'predict', the weights remain the same, while the terms for the new time period grow in the specified order..<br>\nGiven this behavior, it's challenging for me to find practical use cases for polynomial orders other than \"1.\"<br>\n**please share your thoughts in the comments**","metadata":{"_uuid":"d893658e-9b99-499f-bc62-2b131944e993","_cell_guid":"4bdf6fc4-937d-460a-9273-e250af1d2bb8","trusted":true}},{"cell_type":"code","source":"# try different ORDER values to see visualisation of my above statement\nORDER = 3\n\ndp_2 = DeterministicProcess(index = index_,\n                            constant = True, \n                            order = ORDER, \n                            drop = False)\nX_time_1_test = dp.out_of_sample(steps=500)\nX_time_n = dp_2.in_sample()\nX_time_n_test = dp_2.out_of_sample(steps=500)\ndemo_model = LinearRegression (fit_intercept = False).fit(X_time_n, y_train)\n\ny_order_1 = pd.DataFrame(base_model.predict(X_time),index = X_time.index,columns = y_train.columns)\ny_order_1 = y_order_1.stack([0,1]).to_frame().query('family == @FAMILY and store_nbr == @STORE').reset_index(['family', 'store_nbr'],drop=True).squeeze()\n\ny_order_1_fore = pd.DataFrame(base_model.predict(X_time_1_test),index = X_time_1_test.index,columns = y_train.columns)\ny_order_1_fore = y_order_1_fore.stack([0,1]).to_frame().query('family == @FAMILY and store_nbr == @STORE').reset_index(['family', 'store_nbr'],drop=True).squeeze()\n\ny_order_n = pd.DataFrame(demo_model.predict(X_time_n),index = X_time_n.index,columns = y_train.columns)\ny_order_n = y_order_n.stack([0,1]).to_frame().query('family == @FAMILY and store_nbr == @STORE').reset_index(['family', 'store_nbr'],drop=True).squeeze()\n\ny_order_n_fore = pd.DataFrame(demo_model.predict(X_time_n_test),index = X_time_n_test.index,columns = y_train.columns)\ny_order_n_fore = y_order_n_fore.stack([0,1]).to_frame().query('family == @FAMILY and store_nbr == @STORE').reset_index(['family', 'store_nbr'],drop=True).squeeze()\n\ny_fact = y_train.stack([0,1]).to_frame().query('family == @FAMILY and store_nbr == @STORE').reset_index(['family', 'store_nbr'],drop=True).squeeze()\n\nax = y_fact.plot (**plot_params, alpha = 0.3, label=f\"ground truth\")\nax = y_order_1.plot(ax=ax, label=\"Order_1_fit\")\nax = y_order_1_fore.plot(ax=ax, label=\"Order_1_forecast\", color=\"C2\", linewidth = 3)\nax = y_order_n.plot(ax=ax, label=f\"Order_{ORDER}_fit\")\nax = y_order_n_fore.plot(ax=ax, label=f\"Order_{ORDER}_forecast\", color=\"C3\", linewidth = 3)\nax.set_title (f'fits and predictions with a time_dummy for {FAMILY} at store {STORE}')\n_ = ax.legend()","metadata":{"_uuid":"a1cbc322-a357-4169-9886-41afb74d961d","_cell_guid":"3d1d7e86-8939-476d-bf18-cbfdfa712493","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:54.293523Z","iopub.execute_input":"2023-12-19T19:47:54.294018Z","iopub.status.idle":"2023-12-19T19:47:57.109707Z","shell.execute_reply.started":"2023-12-19T19:47:54.293985Z","shell.execute_reply":"2023-12-19T19:47:57.108519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUBMISSION WITH SEASONS ACCOUNTED\n- Public Score (RMSLE): **0.53266**","metadata":{"_uuid":"0c506cba-7914-4829-aed2-c39a4fffb622","_cell_guid":"a42dcb52-ef06-4117-a81a-a46c5378b42a","trusted":true}},{"cell_type":"code","source":"from scipy.signal import periodogram\n\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    fs = pd.Timedelta(\"365D\") / pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual (1)\",\n            \"Semiannual (2)\",\n            \"Quarterly (4)\",\n            \"Bimonthly (6)\",\n            \"Monthly (12)\",\n            \"Biweekly (26)\",\n            \"Weekly (52)\",\n            \"Semiweekly (104)\",\n        ],\n        rotation=30,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram\")\n    return ax","metadata":{"_uuid":"276849b4-b683-41b8-a55b-9ea41c5d9949","_cell_guid":"c9f371ee-c2b2-4882-ad37-759774fd03c1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:57.110978Z","iopub.execute_input":"2023-12-19T19:47:57.111343Z","iopub.status.idle":"2023-12-19T19:47:57.190538Z","shell.execute_reply.started":"2023-12-19T19:47:57.111294Z","shell.execute_reply":"2023-12-19T19:47:57.189156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (f'Periodogram for {FAMILY} at store {STORE} from {START} till {END}')\nplot_periodogram(y_true);","metadata":{"_uuid":"2a3e9610-10a7-4d17-9a73-539d14d7a072","_cell_guid":"9e3d1233-7b29-4948-9c15-1c8800dd6e98","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:57.192867Z","iopub.execute_input":"2023-12-19T19:47:57.193542Z","iopub.status.idle":"2023-12-19T19:47:58.362305Z","shell.execute_reply.started":"2023-12-19T19:47:57.193504Z","shell.execute_reply":"2023-12-19T19:47:58.361089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Capture Seasons with day_of_week","metadata":{"_uuid":"1880eb79-ab2f-4559-a801-b7879a3ea79f","_cell_guid":"c57f61d4-8a44-4d18-8f89-0778886d91ab","trusted":true}},{"cell_type":"code","source":"def seasonal_plot(X, y, period, freq, ax=None):\n    if ax is None:\n        _, ax = plt.subplots()\n    palette = sns.color_palette(\"husl\", n_colors=X[period].nunique(),)\n    ax = sns.lineplot(\n        x=freq,\n        y=y,\n        hue=period,\n        data=X,\n        ci=False,\n        ax=ax,\n        palette=palette,\n        legend=False,\n    )\n    ax.set_title(f\"Seasonal Plot ({period}/{freq}) for {FAMILY} at store {STORE}from {START} till {END}\")\n    for line, name in zip(ax.lines, X[period].unique()):\n        y_ = line.get_ydata()[-1]\n        ax.annotate(\n            name,\n            xy=(1, y_),\n            xytext=(6, 0),\n            color=line.get_color(),\n            xycoords=ax.get_yaxis_transform(),\n            textcoords=\"offset points\",\n            size=14,\n            va=\"center\",\n        )\n    return ax","metadata":{"_uuid":"4ccfd927-8513-44d1-be62-ef8d9221edab","_cell_guid":"4012d4c2-fef4-4cc3-b0d7-25b35260e6b5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:58.363658Z","iopub.execute_input":"2023-12-19T19:47:58.363992Z","iopub.status.idle":"2023-12-19T19:47:58.373944Z","shell.execute_reply.started":"2023-12-19T19:47:58.363964Z","shell.execute_reply":"2023-12-19T19:47:58.3728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = y_true.to_frame()\nX[\"day\"] = X.index.dayofweek  # the x-axis (freq)\nX[\"week\"] = X.index.week  # the seasonal period (period)\nseasonal_plot(X, y=\"ground_truth\", period=\"week\", freq=\"day\");","metadata":{"_uuid":"26f2e166-4710-4b7f-8055-dc7d3949d88b","_cell_guid":"bc79a158-3483-49d8-ab7f-7d80217c67fd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:58.375796Z","iopub.execute_input":"2023-12-19T19:47:58.376412Z","iopub.status.idle":"2023-12-19T19:47:59.764187Z","shell.execute_reply.started":"2023-12-19T19:47:58.376371Z","shell.execute_reply":"2023-12-19T19:47:59.762671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nAdd OHE matrix for day of the week\n\"\"\"\nX_seasonal = dp.in_sample()\n\nday_of_week = pd.Series(X_seasonal.index.dayofweek, index = index_)\nX_day_of_week = pd.get_dummies(day_of_week, prefix = 'day_of_week')\nX_seasonal = pd.concat([X_seasonal, X_day_of_week], axis=1)\n\n# Check\nX_seasonal.shape, X_seasonal.isna().sum().sum()","metadata":{"_uuid":"446e4781-85ff-488f-9921-c802bd3452d6","_cell_guid":"64ad1c15-75a7-4734-b2c4-8dfccdbe85e0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:59.766016Z","iopub.execute_input":"2023-12-19T19:47:59.766533Z","iopub.status.idle":"2023-12-19T19:47:59.782713Z","shell.execute_reply.started":"2023-12-19T19:47:59.766488Z","shell.execute_reply":"2023-12-19T19:47:59.781244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check(X_seasonal)","metadata":{"_uuid":"5932ce3c-a88b-4644-bcf1-778437a56c31","_cell_guid":"010c56ed-e4e2-4b3b-a9a5-5e5ed36c3b58","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:47:59.784615Z","iopub.execute_input":"2023-12-19T19:47:59.785013Z","iopub.status.idle":"2023-12-19T19:48:00.994475Z","shell.execute_reply.started":"2023-12-19T19:47:59.784972Z","shell.execute_reply":"2023-12-19T19:48:00.993144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Capture Seasons with Fourier","metadata":{"_uuid":"9c3abe9f-54ad-4957-b96f-0f1b583e838c","_cell_guid":"8a2da520-578c-4fa2-9dab-e20270ab9cfc","trusted":true}},{"cell_type":"code","source":"from statsmodels.tsa.deterministic import CalendarFourier\n\nfourier = CalendarFourier(freq=\"A\", order=10)            \ndp_fourier = DeterministicProcess(\n            index = index_,\n            constant=False,             \n            order=1,             \n            seasonal=True,                                    \n            additional_terms=[fourier],     \n            drop=True\n)\nX_fourier = dp_fourier.in_sample()\nX_seasonal = pd.concat ([X_seasonal, X_fourier], axis=1)\n\n# Check\nX_seasonal.shape, X_seasonal.isna().sum().sum()","metadata":{"_uuid":"c2303247-9579-4363-a548-eaf2b1f52455","_cell_guid":"6ec02a7f-cd61-449c-a45c-713a04221856","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:01.00353Z","iopub.execute_input":"2023-12-19T19:48:01.00395Z","iopub.status.idle":"2023-12-19T19:48:01.073533Z","shell.execute_reply.started":"2023-12-19T19:48:01.003914Z","shell.execute_reply":"2023-12-19T19:48:01.071614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check(X_seasonal)","metadata":{"_uuid":"239e9a43-fad3-4806-ac27-df5f74587e4d","_cell_guid":"8796d5ac-9793-4823-a0bc-524b2e196c52","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:01.075815Z","iopub.execute_input":"2023-12-19T19:48:01.076257Z","iopub.status.idle":"2023-12-19T19:48:02.346615Z","shell.execute_reply.started":"2023-12-19T19:48:01.076212Z","shell.execute_reply":"2023-12-19T19:48:02.345364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Capture Seasons with holidays\n\n*Pay special attention to the 'transferred' column. A holiday that is transferred officially falls on that calendar day, but was moved to another date by the government. A transferred day is more like a normal day than a holiday.*","metadata":{"_uuid":"4f194007-6adc-44b9-a6ed-8daa96628a49","_cell_guid":"ab119a3c-451a-45fe-803f-9cec61e39dee","trusted":true}},{"cell_type":"code","source":"\"\"\"\nNOTE: This feature covers New Year.\n\"\"\"\nholidays = (holidays_events  \n            .query(\"transferred == False\")                            # drop the transferred holidays, since they are regular days\n            .query(\"locale == 'National'\")                            # keep the National holidays only, since the location of the stores is unknown\n            .loc[:,'description']                                     # keep one column with holidays names\n            .to_frame().assign(description=lambda x: x.description.cat.remove_unused_categories())\n           )\nduplicated_dates = holidays.index.duplicated(keep='first')\nholidays = holidays[~duplicated_dates]\n\nX_holidays = pd.get_dummies (holidays)\nX_seasonal = X_seasonal.join(X_holidays, on='date', how='left').fillna(0.0)   \n\n# Check\nX_seasonal.shape, X_seasonal.isna().sum().sum()","metadata":{"_uuid":"bd989003-7523-4924-89c9-1199c7af74a7","_cell_guid":"a7f06b94-7b66-452f-8edb-ed7bed6c22d4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:02.3486Z","iopub.execute_input":"2023-12-19T19:48:02.348995Z","iopub.status.idle":"2023-12-19T19:48:02.37885Z","shell.execute_reply.started":"2023-12-19T19:48:02.348962Z","shell.execute_reply":"2023-12-19T19:48:02.377679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check(X_seasonal)","metadata":{"_uuid":"613612d8-22f7-4781-9d1f-faad87113ddf","_cell_guid":"5121b8ea-fffe-4a3f-9b6e-a3e658a2ca9f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:02.380215Z","iopub.execute_input":"2023-12-19T19:48:02.38059Z","iopub.status.idle":"2023-12-19T19:48:03.700762Z","shell.execute_reply.started":"2023-12-19T19:48:02.380559Z","shell.execute_reply":"2023-12-19T19:48:03.699566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seasonal_model = LinearRegression (fit_intercept = False).fit(X_seasonal, y_train)\n# joblib.dump(seasonal_model, 'seasonal_model.pkl')","metadata":{"_uuid":"4853e96e-4c1f-4944-bdb6-77e1c6edb3c4","_cell_guid":"0497beba-bde4-4928-97ca-957542b758ff","execution":{"iopub.status.busy":"2023-12-19T19:48:03.702092Z","iopub.execute_input":"2023-12-19T19:48:03.70272Z","iopub.status.idle":"2023-12-19T19:48:03.708436Z","shell.execute_reply.started":"2023-12-19T19:48:03.70268Z","shell.execute_reply":"2023-12-19T19:48:03.70708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create features for test set\n\nX_seasonal_test = dp.out_of_sample(steps=16)\nX_seasonal_test.index.name = 'date'\n\n# deseason with day_of_week\nday_of_week = pd.Series(X_seasonal_test.index.dayofweek, index = X_seasonal_test.index)\nX_day_of_week = pd.get_dummies(day_of_week, prefix = 'day_of_week')\nX_seasonal_test = pd.concat([X_seasonal_test, X_day_of_week], axis=1)\n\n# deseason with fourier\nX_fourier_test = dp_fourier.out_of_sample(16)\nX_seasonal_test = pd.concat ([X_seasonal_test, X_fourier_test], axis=1)\n\n# deseason with holidays\nX_seasonal_test.index.name = 'date'\nX_seasonal_test = X_seasonal_test.join(X_holidays, on='date', how='left').fillna(0.0)","metadata":{"_uuid":"7507aa84-43db-4c29-910d-a5f3815057cb","_cell_guid":"25fe6b26-332f-4220-b4ee-93cf8eb8e6ed","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:03.709928Z","iopub.execute_input":"2023-12-19T19:48:03.710535Z","iopub.status.idle":"2023-12-19T19:48:03.73596Z","shell.execute_reply.started":"2023-12-19T19:48:03.710497Z","shell.execute_reply":"2023-12-19T19:48:03.734638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seasonal_model = joblib.load('/kaggle/input/timeseriescourse-models/seasonal_model.pkl')\ny_seasonal_fore = pd.DataFrame(seasonal_model.predict(X_seasonal_test),               \n                        index = X_seasonal_test.index,      \n                        columns = y_train.columns).clip(0.0)","metadata":{"_uuid":"72c77a28-54ab-4e71-a360-5b91e73aae23","_cell_guid":"b97ecc81-5e90-4062-b22a-f4dd2c196619","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:03.738114Z","iopub.execute_input":"2023-12-19T19:48:03.738538Z","iopub.status.idle":"2023-12-19T19:48:03.790678Z","shell.execute_reply.started":"2023-12-19T19:48:03.738503Z","shell.execute_reply":"2023-12-19T19:48:03.788927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_1 = (y_seasonal_fore\n            .stack(['family', 'store_nbr'])\n            .to_frame()\n            .join(test.id)\n            .rename(columns = {0:'sales'})\n            .reset_index(drop=True)\n            .reindex(columns = ['id','sales'])\n            )\n# submission_1.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"_uuid":"adc66083-2b40-4c71-93b5-72e2c5e721e4","_cell_guid":"10406aea-40f7-4a14-a8d7-f48be23bf9fb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:03.792674Z","iopub.execute_input":"2023-12-19T19:48:03.794684Z","iopub.status.idle":"2023-12-19T19:48:03.868675Z","shell.execute_reply.started":"2023-12-19T19:48:03.794612Z","shell.execute_reply":"2023-12-19T19:48:03.866452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUBMISSION WITH VULCANO\n- Public Score (RMSLE): **0.53218** (best result)\n\n*A magnitude 7.8 earthquake struck Ecuador on `April 16, 2016`. People rallied in relief efforts donating water and other first need products which greatly affected supermarket sales for several weeks after the earthquake*","metadata":{"_uuid":"f3fcec0c-7ba5-4ee0-b9fa-64a3461d14e7","_cell_guid":"1d1ca273-5276-490d-8191-d256e4bf7d20","trusted":true}},{"cell_type":"markdown","source":"## Add OHE for Eruption with 21-lags","metadata":{"_uuid":"b99d6d4d-97cb-47e4-a79f-4286b05fda11","_cell_guid":"e1b8b05e-a1c2-4b63-9f04-dbb4c03a3fea","trusted":true}},{"cell_type":"code","source":"def make_lags(ts, lags, prefix = None):\n    return pd.concat({\n            f'{prefix}_lag_{i}': ts.shift(i)\n            for i in lags\n        },\n        axis=1)\n\nvulcano = pd.DataFrame((X_time.index == '2016-04-16')*1.0, index = index_, columns = ['vulcano'])\nX_vulcano_ = make_lags (vulcano.squeeze(), lags = range(22), prefix = 'vulcano')\nX_vulcano_ = X_vulcano_.fillna(0.0)\n\n# Check\n# start = pd.Period('2016-04-16', freq='D')\n# X_vulcano.loc[start:start+21]","metadata":{"_uuid":"4aaf2d84-6d62-4c02-a480-515232dc96ba","_cell_guid":"88c60c0b-a31d-401c-9a89-90f19a4be6de","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:03.871015Z","iopub.execute_input":"2023-12-19T19:48:03.872543Z","iopub.status.idle":"2023-12-19T19:48:03.898602Z","shell.execute_reply.started":"2023-12-19T19:48:03.872469Z","shell.execute_reply":"2023-12-19T19:48:03.897169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_vulcano = pd.concat([X_seasonal, X_vulcano_], axis = 1)\nX_vulcano.shape, X_vulcano.isna().sum().sum()","metadata":{"_uuid":"9aac6ce9-763b-4e0c-86a3-0e1b4f81a61a","_cell_guid":"cb0c4584-e809-4616-99ed-df2955ae13e3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:03.899769Z","iopub.execute_input":"2023-12-19T19:48:03.900329Z","iopub.status.idle":"2023-12-19T19:48:03.912123Z","shell.execute_reply.started":"2023-12-19T19:48:03.900283Z","shell.execute_reply":"2023-12-19T19:48:03.910907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check(X_vulcano)","metadata":{"_uuid":"94a35fd0-d2b9-403d-8177-7d3cf4e7b1df","_cell_guid":"81272d65-37de-4f35-ba31-a3c15fa91f3b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:03.913496Z","iopub.execute_input":"2023-12-19T19:48:03.914881Z","iopub.status.idle":"2023-12-19T19:48:05.272Z","shell.execute_reply.started":"2023-12-19T19:48:03.914834Z","shell.execute_reply":"2023-12-19T19:48:05.270359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vulcano_model = LinearRegression (fit_intercept = False).fit(X_vulcano, y_train)\n# joblib.dump(vulcano_model, 'vulcano_model.pkl')","metadata":{"_uuid":"deaee4e2-ef78-4d9e-9d4f-2d62eac491b0","_cell_guid":"23badbd2-8fa9-46b7-a2c6-45c7d38d6a6a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:05.273964Z","iopub.execute_input":"2023-12-19T19:48:05.275311Z","iopub.status.idle":"2023-12-19T19:48:05.281229Z","shell.execute_reply.started":"2023-12-19T19:48:05.275253Z","shell.execute_reply":"2023-12-19T19:48:05.279693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add vulcano to the test set\nX_vulcano_test = X_seasonal_test.join(X_vulcano_, on='date', how='left')\nX_vulcano_test = X_vulcano_test.fillna(0.0)\n\nX_vulcano_test.shape, X_vulcano_test.isna().sum().sum()","metadata":{"_uuid":"b43ced7c-d6d3-4bb9-a695-108d67b58af9","_cell_guid":"9067b64f-7009-4994-906a-d9e4b74d10a3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:05.283123Z","iopub.execute_input":"2023-12-19T19:48:05.283583Z","iopub.status.idle":"2023-12-19T19:48:05.301969Z","shell.execute_reply.started":"2023-12-19T19:48:05.283531Z","shell.execute_reply":"2023-12-19T19:48:05.300423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vulcano_model = joblib.load ('/kaggle/input/timeseriescourse-models/vulcano_model.pkl')\ny_vulcano_fore = pd.DataFrame(vulcano_model.predict(X_vulcano_test),               \n                        index = X_vulcano_test.index,      \n                        columns = y_train.columns).clip(0.0)","metadata":{"_uuid":"9803e82b-d53c-47e5-b9b8-de3ebd8962f1","_cell_guid":"8a94782f-358b-4a0a-90e0-3a2105964173","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:05.303785Z","iopub.execute_input":"2023-12-19T19:48:05.304834Z","iopub.status.idle":"2023-12-19T19:48:05.357722Z","shell.execute_reply.started":"2023-12-19T19:48:05.304785Z","shell.execute_reply":"2023-12-19T19:48:05.355961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_2 = (y_vulcano_fore\n            .stack(['family', 'store_nbr'])\n            .to_frame()\n            .join(test.id)\n            .rename(columns = {0:'sales'})\n            .reset_index(drop=True)\n            .reindex(columns = ['id','sales'])\n            )\n#best score\nsubmission_2.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"_uuid":"12ee5545-4fdb-43ab-8c44-d1822163e311","_cell_guid":"6098e4dd-53e2-47c0-b113-7736edfef6ef","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:05.360505Z","iopub.execute_input":"2023-12-19T19:48:05.361599Z","iopub.status.idle":"2023-12-19T19:48:05.56681Z","shell.execute_reply.started":"2023-12-19T19:48:05.361534Z","shell.execute_reply":"2023-12-19T19:48:05.565516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUBMISSION WITH MULTISTEP TARGET\n- Public Score (RMSLE): **0.55745**\n\nThe training set ends on `2017-08-15`, which gives us the forecast **origin**.<br> The test set comprises the dates `2017-08-16` to `2017-08-31`, and this gives us the **forecast horizon**. <br>\nThere is one step between the origin and horizon, so we have a **lead time of one day**. <br>Put another way, we need a *`16-step forecast with a 1-step lead time`*.","metadata":{"_uuid":"1a5ecb30-1fc0-4414-908d-111b8cc8f1a5","_cell_guid":"34ece988-4a88-42c9-ab22-34b69f567aeb","trusted":true}},{"cell_type":"markdown","source":"# *A theoretical issue*: **Algorithm's Complexity**\nRemember we said that to deal with temporal dependence with LinReg you need **X** and **y** that have simple PeriodIndex in axis=1. All other categories go 'wide' (axis=0). I think of this in a way that one row should contain everything that happened that day. <br>\n\nNow, in our data set we have 54 stores and 33 'families' which brings us to their product - **1782** values per row in our initial BASELINE setting.<br>\n\nWhat happens when we introduce multistep target? Exectly! We should multiply that number by the number of the steps. If we take 16 steps-forecast, then we will end up with **28 512** values per row, essentially meaning, that we will run **28 512** different regressions. 1 month forecast will cost us **53 460** parallel regressions at a time.\n\nIf I'm not mistaken, the Complexity of this algorithm can be described as:<br> \n                            \n                            O(n*m*k)\n                               \nwhere:<br>\n`n` - number of categorical features<br>\n`m` - number of categories in each of the features <br>\n`k` - number of your shifted features (lags, leads, rolling statistics)\n\nIn order to shrink down the numbers, you have 3 straightforward options:\n1. Reduce `n` by averaging across some categories \n2. Reduce `m` by more coarse grouping\n2. Reduce the number of steps in the forecast.\n\nWhile 1. and 2. may be just meaningless, we will talk about №3 in the section **`Complexity Vs Error Propagation`**\n\n4. An alternative approach involves reducing dimensionality using __Single Value Decomposition (SVD)__, such as PCA and TruncatedSVD. While these methods are powerful, they introduce challenges related to result interpretation and monitoring data loss. This is a complex topic that can be explored in depth in another notebook.","metadata":{}},{"cell_type":"code","source":"# Off top: check this series for more on SVD\nfrom IPython.display import HTML\nyoutube_video_id = \"nbBvuuNVfco?si=zAxPfuv4OXiBbgyI\"\nHTML(f'<iframe width=\"300\" height=\"250\" src=\"https://www.youtube.com/embed/{youtube_video_id}\" frameborder=\"0\" allowfullscreen></iframe>')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T22:02:31.377831Z","iopub.execute_input":"2023-12-19T22:02:31.37837Z","iopub.status.idle":"2023-12-19T22:02:31.389273Z","shell.execute_reply.started":"2023-12-19T22:02:31.378306Z","shell.execute_reply":"2023-12-19T22:02:31.388101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_multistep_target(ts, steps):\n    return pd.concat(\n        {f'y_step_{i + 1}': ts.shift(-i)\n         for i in range(steps)},\n        axis=1)\n\ndef plot_multistep(y, every=1, ax=None, palette_kwargs=None):\n    palette_kwargs_ = dict(palette='husl', n_colors=16, desat=None)\n    if palette_kwargs is not None:\n        palette_kwargs_.update(palette_kwargs)\n    palette = sns.color_palette(**palette_kwargs_)\n    if ax is None:\n        fig, ax = plt.subplots()\n    ax.set_prop_cycle(plt.cycler('color', palette))\n    for date, preds in y[::every].iterrows():\n        preds.index = pd.period_range(start=date, periods=len(preds))\n        preds.plot(ax=ax)\n    return ax\n\ndef check_multistep (\n            data,    \n            y = y_train,\n            START = START, \n            END = END,\n            FAMILY = FAMILY,\n            STORE = STORE,\n            EVERY = 16\n):\n       \n    fit = (data\n           .stack(['family', 'store_nbr'])\n           .query('family == @FAMILY and store_nbr == @STORE')\n           .reset_index(['family', 'store_nbr'], drop=True)\n           .loc[START:END]\n          )\n\n    y = (y\n         .stack(['family', 'store_nbr'])\n         .to_frame()\n         .query('family == @FAMILY and store_nbr == @STORE')\n         .reset_index(['family', 'store_nbr'],drop=True)\n         .rename(columns={0:'ground_truth'})\n         .loc[START:END]\n         .squeeze()\n        )\n\n    fig, ax = plt.subplots(1, 1, figsize=(11, 4))\n    ax = y.plot(**plot_params, ax=ax, alpha=0.5)\n    ax = plot_multistep(fit, ax=ax, every=EVERY)\n    ax.set_title (f'16-days forecasts against ground-truth for {FAMILY} from {START} till {END}')\n    \n# Takes one forecast on START day and renames all 'lag_{i}' columns by corresponding dates.     \ndef fetch_forecast (\n        data,\n        START = '2017-08-16',\n        END = '2017-08-31'):\n    \n    X = data.loc[START]\n    DATES = pd.period_range (START, END)                                # this is needed for iteration through a list of all \n    index_to_rename = X.index.get_level_values(0).unique()[:len(DATES)] # dates in the horizon (when calculating an average)\n    rename_dict = dict(zip(index_to_rename, DATES))\n\n    forecast = X.rename(rename_dict, level = 0).to_frame()\n    forecast.index = forecast.index.set_names('date',level = 0)\n    \n    return forecast","metadata":{"_uuid":"ae6cebb2-174e-4518-8e16-15c880244f88","_cell_guid":"dc980675-00db-4696-ade9-0d21b7ff20e5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:05.568788Z","iopub.execute_input":"2023-12-19T19:48:05.56914Z","iopub.status.idle":"2023-12-19T19:48:05.587669Z","shell.execute_reply.started":"2023-12-19T19:48:05.569102Z","shell.execute_reply":"2023-12-19T19:48:05.586075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It gets shorter after dropping NANs. Hence are all further '.align()' methods\ny_train_multi = make_multistep_target(y_train, steps=16).dropna() ","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:05.589249Z","iopub.execute_input":"2023-12-19T19:48:05.589712Z","iopub.status.idle":"2023-12-19T19:48:06.150137Z","shell.execute_reply.started":"2023-12-19T19:48:05.589668Z","shell.execute_reply":"2023-12-19T19:48:06.149023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_multi, X_vulcano_cut = y_train_multi.align(X_vulcano, join='inner', axis=0)","metadata":{"_uuid":"d7f23f66-52a4-4874-9ed9-dcb15154ed05","_cell_guid":"99af37b5-6354-484b-921e-27b3a591dda6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:06.151777Z","iopub.execute_input":"2023-12-19T19:48:06.152114Z","iopub.status.idle":"2023-12-19T19:48:06.244306Z","shell.execute_reply.started":"2023-12-19T19:48:06.152085Z","shell.execute_reply":"2023-12-19T19:48:06.243193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_vulcano_cut has 'const' column, which works to calculate y-intercept\n# model_multi = LinearRegression (fit_intercept = False).fit(X_vulcano_cut, y_train_multi)\n# joblib.dump(model_multi, \"model_multi.pkl\")","metadata":{"_uuid":"1af52c1f-c92f-4711-8f3c-4195488d9b0f","_cell_guid":"102b8805-918c-4f4b-b682-5abafd860c1a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:06.246108Z","iopub.execute_input":"2023-12-19T19:48:06.246473Z","iopub.status.idle":"2023-12-19T19:48:06.253061Z","shell.execute_reply.started":"2023-12-19T19:48:06.246443Z","shell.execute_reply":"2023-12-19T19:48:06.251888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_multi = joblib.load('/kaggle/input/timeseriescourse-models/model_multi.pkl')\ny_multi_fit = pd.DataFrame(model_multi.predict(X_vulcano_cut),               \n                        index = X_vulcano_cut.index,      \n                        columns = y_train_multi.columns).clip(0.0)","metadata":{"_uuid":"7ef49b8e-81c3-4b10-be7e-9db2095e20f2","_cell_guid":"41f56dd4-e434-4f43-a113-eef82ecf6e84","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:06.254883Z","iopub.execute_input":"2023-12-19T19:48:06.255207Z","iopub.status.idle":"2023-12-19T19:48:07.420829Z","shell.execute_reply.started":"2023-12-19T19:48:06.255179Z","shell.execute_reply":"2023-12-19T19:48:07.419137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_multistep (y_multi_fit)","metadata":{"_uuid":"4c588beb-935f-41d9-82ce-99b3e2fd9433","_cell_guid":"a4f41dc7-07d9-45a4-a9df-3a26cae86f6c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:07.424497Z","iopub.execute_input":"2023-12-19T19:48:07.426017Z","iopub.status.idle":"2023-12-19T19:48:12.655754Z","shell.execute_reply.started":"2023-12-19T19:48:07.425963Z","shell.execute_reply":"2023-12-19T19:48:12.654492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_multi_fore = pd.DataFrame(model_multi.predict(X_vulcano_test),               \n                        index = X_vulcano_test.index,      \n                        columns = y_train_multi.columns).clip(0.0)","metadata":{"_uuid":"2c7e16cc-1518-41f1-8efa-49e367cd8fe1","_cell_guid":"eb4e530c-ae4f-4b5f-8ed3-45a2c803da3d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:12.657443Z","iopub.execute_input":"2023-12-19T19:48:12.658036Z","iopub.status.idle":"2023-12-19T19:48:12.817973Z","shell.execute_reply.started":"2023-12-19T19:48:12.657994Z","shell.execute_reply":"2023-12-19T19:48:12.816808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_3 = (fetch_forecast(y_multi_fore)\n                  .join(test.id)\n                  .reset_index(drop=True)\n               )\n\nsubmission_3['sales'] = submission_3.iloc[:,0]\nsubmission_3 = submission_3[['id','sales']]\n# submission_3.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"_uuid":"f808043f-ba3c-4d48-a53b-25541fced9a1","_cell_guid":"b2d6a092-a519-4f4c-96e1-088863806f0f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:12.819378Z","iopub.execute_input":"2023-12-19T19:48:12.820993Z","iopub.status.idle":"2023-12-19T19:48:13.102668Z","shell.execute_reply.started":"2023-12-19T19:48:12.820953Z","shell.execute_reply":"2023-12-19T19:48:13.101383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bonus: forecasts averaged\n- Public Score (RMSLE): **0.55769** (no improvement)","metadata":{"_uuid":"b2dc93a5-95bf-470b-9daf-8d4bf5cce875","_cell_guid":"5beb350b-b59c-4b8c-92da-4869474a8137","trusted":true}},{"cell_type":"code","source":"'''\nThis is where we iterate through a list of dates, fetching forecasts and renaming their \n'lag_{i}' columns with pertinent dates\n'''\nrange_ = [str(period) for period in pd.period_range ('2017-08-16', '2017-08-31')]\nforecasts = [fetch_forecast (y_multi_fore, START=i) for i in range_]","metadata":{"_uuid":"617b1c00-511c-45cd-850e-52ea9aefcab2","_cell_guid":"63ea56b9-7299-4b39-985a-b3686614b0d2","collapsed":false,"_kg_hide-input":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:13.104354Z","iopub.execute_input":"2023-12-19T19:48:13.104825Z","iopub.status.idle":"2023-12-19T19:48:15.294075Z","shell.execute_reply.started":"2023-12-19T19:48:13.104787Z","shell.execute_reply":"2023-12-19T19:48:15.292516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nice tool from the course. Here is how it may be applied\nimport ipywidgets as widgets\n\ndata_tabs = widgets.Tab([widgets.Output() for _ in enumerate(forecasts)])\nfor i, df in enumerate(forecasts):\n    data_tabs.set_title(i, f'forecast {i+1}')\n    with data_tabs.children[i]:\n        display(df)\n\ndisplay(data_tabs)","metadata":{"_uuid":"ee23b709-ce14-4ce9-b3d0-b2e55f292519","_cell_guid":"59972044-39da-42b5-9a94-9f8c80047080","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:15.2957Z","iopub.execute_input":"2023-12-19T19:48:15.296046Z","iopub.status.idle":"2023-12-19T19:48:15.64297Z","shell.execute_reply.started":"2023-12-19T19:48:15.296017Z","shell.execute_reply":"2023-12-19T19:48:15.641717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full = forecasts[0]\n\nfor forecast in forecasts[1:]:\n    full = full.merge(forecast, left_index=True, right_index=True, how='left')\n\nsubmission_4 = pd.DataFrame (full.mean(axis=1), columns = ['sales'])\nsubmission_4 = submission_4.join(test.id).reset_index(drop=True)\n# submission_4.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"_uuid":"9e1c10eb-7023-4834-aefe-f84c7b27bc2c","_cell_guid":"fe2411c6-71ac-4ad6-865a-5d7952910fb8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-19T19:48:15.644369Z","iopub.execute_input":"2023-12-19T19:48:15.64479Z","iopub.status.idle":"2023-12-19T19:48:31.632415Z","shell.execute_reply.started":"2023-12-19T19:48:15.644759Z","shell.execute_reply":"2023-12-19T19:48:31.630726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUBMISSION WITH BOOSTED HYBRID\n- Public Score (RMSLE): **0.55867**","metadata":{}},{"cell_type":"code","source":"\"\"\"\nWhile the linear regression algorithm is capable of multi-output regression, \nthe XGBoost algorithm is not. To predict multiple series at once with XGBoost, \nwe'll instead convert these series from wide format, with one time series per column, \nto long format, with series indexed by categories along rows.\n\"\"\"\n\nclass BoostedHybrid:\n    def __init__(self, model_1, model_2):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.y_columns = None  # store column names from fit method\n        \n    def fit(self, X_1, X_2, y):\n        self.model_1.fit(X_1, y)\n        y_fit = pd.DataFrame(                          # make predictions with self.model_1\n                    self.model_1.predict(X_1),\n                    index=X_1.index, \n                    columns=y.columns\n        )\n        y_resid = y - y_fit                             # compute residuals\n        y_resid = y_resid.stack([0,1])                  # wide to long. (level=[0,1]) - to pivot both 'family' and 'store_nbr'\n        \n        X_2_train, X_2_val, y_resid_train, y_resid_val = train_test_split(X_2, y_resid, test_size=0.2, shuffle=False)\n\n        self.model_2.fit(X_2_train, y_resid_train,     # fit self.model_2 on residuals\n                         early_stopping_rounds=5,      # This is an XGB feature\n                         eval_set=[(X_2_val, y_resid_val)], # that works in pair with this one\n                         verbose=False)\n\n        self.y_columns = y.columns                     # Save column names for predict method\n        self.y_fit = y_fit                             # Save data\n        self.y_resid = y_resid\n        \n        \n    def predict(self, X_1, X_2):\n        y_pred = pd.DataFrame(\n            self.model_1.predict(X_1),\n            index=X_1.index, \n            columns=self.y_columns,\n        )\n        y_pred = y_pred.stack([0,1])\n        y_pred += self.model_2.predict(X_2)\n        \n        return y_pred","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:31.634121Z","iopub.execute_input":"2023-12-19T19:48:31.634571Z","iopub.status.idle":"2023-12-19T19:48:31.64773Z","shell.execute_reply.started":"2023-12-19T19:48:31.634532Z","shell.execute_reply":"2023-12-19T19:48:31.646403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nAs soon as we have 'early_stopping' hyperparameter for XGB, \nthe value of 'n_estimators' becomes less significant. \n'''\nmodel_BH = BoostedHybrid(\n            model_1=LinearRegression(fit_intercept = False),\n            model_2=XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:31.649579Z","iopub.execute_input":"2023-12-19T19:48:31.650077Z","iopub.status.idle":"2023-12-19T19:48:31.665877Z","shell.execute_reply.started":"2023-12-19T19:48:31.65003Z","shell.execute_reply":"2023-12-19T19:48:31.664239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nSo that XGBoost can learn to distinguish between FAMILIES and STORES, \nwe'll duplicate these levels of MultiIndex with categorical features with a label encoding. \n\"\"\"\n\nfrom sklearn.preprocessing import LabelEncoder\n\nX_2 = train[['onpromotion']]\n\nle_family = LabelEncoder()\nX_2['family_fact'] = X_2.index.get_level_values('family')\nX_2['family_fact'] = le_family.fit_transform(X_2['family_fact'])\nX_2['store_fact'] = X_2.index.get_level_values('store_nbr').astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:31.667804Z","iopub.execute_input":"2023-12-19T19:48:31.668346Z","iopub.status.idle":"2023-12-19T19:48:32.790735Z","shell.execute_reply.started":"2023-12-19T19:48:31.668287Z","shell.execute_reply":"2023-12-19T19:48:32.789422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_2_test = test[['onpromotion']]\n\nX_2_test['family_fact'] = X_2_test.index.get_level_values('family')\nX_2_test['family_fact'] = le_family.transform(X_2_test['family_fact'])\nX_2_test['store_fact'] = X_2_test.index.get_level_values('store_nbr').astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:32.7924Z","iopub.execute_input":"2023-12-19T19:48:32.792753Z","iopub.status.idle":"2023-12-19T19:48:32.812395Z","shell.execute_reply.started":"2023-12-19T19:48:32.792724Z","shell.execute_reply":"2023-12-19T19:48:32.811457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_BH.fit(X_vulcano, X_2, y_train)\n# joblib.dump (model_BH, 'BoostedHybrid.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:32.81365Z","iopub.execute_input":"2023-12-19T19:48:32.814372Z","iopub.status.idle":"2023-12-19T19:48:32.819684Z","shell.execute_reply.started":"2023-12-19T19:48:32.814207Z","shell.execute_reply":"2023-12-19T19:48:32.81815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_BH = joblib.load('/kaggle/input/timeseriescourse-models/BoostedHybrid.pkl')\ny_BH_fit = model_BH.predict(X_vulcano, X_2).to_frame().clip(0.0)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:32.821065Z","iopub.execute_input":"2023-12-19T19:48:32.821441Z","iopub.status.idle":"2023-12-19T19:48:34.260173Z","shell.execute_reply.started":"2023-12-19T19:48:32.821407Z","shell.execute_reply":"2023-12-19T19:48:34.258822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nHere we pass the models' fit TO the ckeck() function, \nso no fitting INSIDE of the function is required.\n\"\"\"\ncheck (y_BH_fit, \n       y = y_train, \n       STORE = STORE, \n       FIT=False, \n       Prefix = f'BOOSTED HYBRID Model fit')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:34.261711Z","iopub.execute_input":"2023-12-19T19:48:34.26208Z","iopub.status.idle":"2023-12-19T19:48:35.787181Z","shell.execute_reply.started":"2023-12-19T19:48:34.262039Z","shell.execute_reply":"2023-12-19T19:48:35.786278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_BH_fore = model_BH.predict(X_vulcano_test, X_2_test).clip(0.0)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:35.788435Z","iopub.execute_input":"2023-12-19T19:48:35.789441Z","iopub.status.idle":"2023-12-19T19:48:35.883506Z","shell.execute_reply.started":"2023-12-19T19:48:35.789393Z","shell.execute_reply":"2023-12-19T19:48:35.882377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_5 = (y_BH_fore \n            .to_frame()\n            .join(test.id)\n            .rename(columns = {0:'sales'})\n            .reset_index(drop=True)\n            .reindex(columns = ['id','sales'])\n            )\n# submission_5.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:35.885109Z","iopub.execute_input":"2023-12-19T19:48:35.885533Z","iopub.status.idle":"2023-12-19T19:48:35.918303Z","shell.execute_reply.started":"2023-12-19T19:48:35.885499Z","shell.execute_reply":"2023-12-19T19:48:35.916692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUBMISSION WITH STACKED HYBRID\n- Public Score (RMSLE): **0.53234**","metadata":{}},{"cell_type":"code","source":"''' \nIt's similar to the boosted model above, with one key difference: \nWe include model_1's prediction as a feature in X_2_train instead of subtracting it from y_train.\n'''\nclass StackedHybrid:\n    def __init__(self, model_1, model_2):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.y_columns = None  # store column names from fit method\n        \n    def fit(self, X_1, X_2, y):\n        self.model_1.fit(X_1, y)\n        y_fit = pd.DataFrame(                          \n                    self.model_1.predict(X_1),\n                    index=X_1.index, \n                    columns=y.columns\n        )\n    \n        y_long = y_fit.stack(level=[0,1])              \n        \n        X_2 = pd.concat([X_2, y_long], axis=1)         # HERE IS WHY THE MODEL IS STACKED\n            \n        X_2_train, X_2_val, y_long_train, y_long_val = train_test_split(X_2, y_long, test_size=0.2, shuffle=False)\n\n        self.model_2.fit(X_2_train, y_long_train,     \n                         early_stopping_rounds=3,       \n                         eval_set=[(X_2_val, y_long_val)], \n                         verbose=False)\n\n        self.y_columns = y.columns                    \n        self.y_fit = y_fit                           \n        self.y_long = y_long\n        \n        \n    def predict(self, X_1, X_2):\n        y_pred = pd.DataFrame(\n            self.model_1.predict(X_1),\n            index=X_1.index, \n            columns=self.y_columns,\n        )\n        y_pred = y_pred.stack([0,1])\n        \n        X_2_augm = pd.concat([X_2, y_pred], axis=1)\n        \n        y_pred_2 = pd.Series(\n            self.model_2.predict(X_2_augm),\n            index=X_2.index)\n        \n        return y_pred_2","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:35.921307Z","iopub.execute_input":"2023-12-19T19:48:35.92182Z","iopub.status.idle":"2023-12-19T19:48:35.935277Z","shell.execute_reply.started":"2023-12-19T19:48:35.921773Z","shell.execute_reply":"2023-12-19T19:48:35.934052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_SH = StackedHybrid(\n            model_1=LinearRegression(fit_intercept = False),\n            model_2=XGBRegressor(n_estimators = 50, learning_rate=0.05, n_jobs=4)\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:35.93685Z","iopub.execute_input":"2023-12-19T19:48:35.937363Z","iopub.status.idle":"2023-12-19T19:48:35.950238Z","shell.execute_reply.started":"2023-12-19T19:48:35.937301Z","shell.execute_reply":"2023-12-19T19:48:35.949019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_SH.fit(X_vulcano, X_2, y_train)\n# joblib.dump (model_SH, 'StackedHybrid.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:35.951871Z","iopub.execute_input":"2023-12-19T19:48:35.952279Z","iopub.status.idle":"2023-12-19T19:48:35.962933Z","shell.execute_reply.started":"2023-12-19T19:48:35.952246Z","shell.execute_reply":"2023-12-19T19:48:35.961966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_SH = joblib.load('/kaggle/input/timeseriescourse-models/StackedHybrid.pkl')\ny_stacked_hybrid_fit = (model_SH\n                    .predict(X_vulcano, X_2)\n                    .to_frame()\n                    .rename(columns = {0: 'STACKED HYBRID fit'})\n                   )","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:35.964547Z","iopub.execute_input":"2023-12-19T19:48:35.965234Z","iopub.status.idle":"2023-12-19T19:48:39.189489Z","shell.execute_reply.started":"2023-12-19T19:48:35.965199Z","shell.execute_reply":"2023-12-19T19:48:39.188478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nBoosted Hybrid looked better\n\"\"\"\ncheck (y_stacked_hybrid_fit, \n       y = y_train, \n       STORE = STORE, \n       FIT = False,\n       Prefix = f'STACKED HYBRID Model fit'\n      )","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:39.190932Z","iopub.execute_input":"2023-12-19T19:48:39.191699Z","iopub.status.idle":"2023-12-19T19:48:40.723884Z","shell.execute_reply.started":"2023-12-19T19:48:39.191658Z","shell.execute_reply":"2023-12-19T19:48:40.722502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_stacked_hybrid = model_SH.predict(X_vulcano_test, X_2_test).clip(0.0)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:40.725552Z","iopub.execute_input":"2023-12-19T19:48:40.725974Z","iopub.status.idle":"2023-12-19T19:48:40.864236Z","shell.execute_reply.started":"2023-12-19T19:48:40.725938Z","shell.execute_reply":"2023-12-19T19:48:40.86318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_6 = (y_stacked_hybrid\n            .to_frame()\n            .join(test.id)\n            .rename(columns = {0:'sales'})\n            .reset_index(drop=True)\n            .reindex(columns = ['id','sales'])\n            )\n# submission_6.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:40.865792Z","iopub.execute_input":"2023-12-19T19:48:40.866482Z","iopub.status.idle":"2023-12-19T19:48:40.881097Z","shell.execute_reply.started":"2023-12-19T19:48:40.866446Z","shell.execute_reply":"2023-12-19T19:48:40.87993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUBMISSION WITH BOOSTED HYBRID AND MULTISTEP TARGET\n- Public Score (RMSLE): **0.79814**","metadata":{}},{"cell_type":"markdown","source":"# *A theoretical issue*: **Complexity Vs Error Propagation**\n\n**four common strategies**\nThe course introduces 4 theoretical consepts of forecasting:<br>\n*Multioutput model, Direct Strategy, Recursive Strategy* and *DirRec Strategy*.\n\nIn my humble opinion, there are only two real concepts here:\n\n1. `Multioutput model` and `Direct Strategy` **is the same thing**. Even if we make one .fit() in our code, we are still running as many models as there are steps in `y`. No matter what model we use. Even Neural Networks in their multiple outputs produce destribution of a probability (which is 1 destributed among all the classes). No model can give you several UNRELATED values in an output. Otherwise, how should your Error Function work? **Please, correct me if I am wrong**\n\n2. `Recursive Strategy` and `DirRec Strategy` is also **the same thing**. You give a forecast as input to your model to make a new forecast. The difference is how many steps your `y` has, how many you give the model at a time. If one - it's *recursive*, if several - it's *DirRec*. In my humble opinion, it is the same strategy and the number of steps is just a Complexity Vs Error compromise, informed by computation resourses at your disposale.\n\n**Error Propagation**\nWhen you pass a LinReg's own prediction as an input to itself multiple times, you can calculate the error accumulation as a progression. This allows you to create a statistically supported Confidence Interval for your forecast. However, if you do the same with XGBoost, you can't estimate the accumulated error because XGBoost doesn't rely on functional dependencies. It only knows that when `X` is **A**, `y` should be somewhere close to **B** and when `X` is **A1**, `y` should be somewhere close to **B2**. The difference between A1 and A2 may be very small, and the difference between B1 and B2 can be significant, and it won't be the same for the next interval. So when your erroneous input randomly assumes the value of A2, your model's output goes crazy. And then you feed that sick output back to the model for the next prediction. \n\nMy assumption is that error propagation with XGBoost is unpredictable or ridiculously complex to control. And this is why you would want to avoid or at least minimize it as much as possible.\n\nHow can you do that? By reducing the number of fits with forecasts. And here comes the **trade off**:\n1. Idially, you would want your model to produce a forecast for the entire horizon (all 16 days at once in our case). But each day is another model, which may be too much for your hardware.\n2. If you predict for one day only and then staff XGB with it's own error 16 times in a line, it will give you garbage in the end.\n3. The compromise is to make as long a MultiStep Target, as your machine can handle and to reduce the number of iterations where forecasts are fed back into the model as much as possible. For example, if you can't afford a 16-day forecast all at once, you can create an 8-day forecast with only one (re)fitting iteration. \n\nTherefore, the 'DirRec strategy' appears more as a technical decision rather than a strategy in the traditional sense. It's akin to adjusting the size of your training set to match your computational capabilities. \n\n**Please share your ideas about these considerations**","metadata":{}},{"cell_type":"code","source":"class MultiBoostedHybrid:\n    def __init__(self, model_1, model_2):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.y_columns = None\n        self.y_columns_stacked = None                   # This is NEW\n        \n    def fit(self, X_1, X_2, y):\n        self.model_1.fit(X_1, y)\n        y_fit = pd.DataFrame(                          \n                    self.model_1.predict(X_1),\n                    index=X_1.index, \n                    columns=y.columns\n        )\n        y_resid = y - y_fit                             \n        y_resid = y_resid.stack(['family','store_nbr']) # Specified level names explicitly to avoid confucion. \n                                                        # Otherwise 'lags' may go 'wide'.\n        \n        self.model_2.fit(X_2, y_resid )                 \n\n        self.y_columns = y.columns                      \n        self.y_columns_stacked = y_resid.columns\n        \n        self.y_fit = y_fit                           \n        self.y_resid = y_resid\n        \n        \n    def predict(self, X_1, X_2):\n        y_pred_1 = pd.DataFrame(\n            self.model_1.predict(X_1),\n            index=X_1.index, \n            columns=self.y_columns,\n        )\n                \n        y_pred_2 = pd.DataFrame(\n            self.model_2.predict(X_2),\n            index=X_2.index, \n            columns=self.y_columns_stacked            # Here is where this NEW is required. \n        )\n        \n        y_pred_1 = y_pred_1.stack(['family','store_nbr'])\n        \n        y_pred = y_pred_1 + y_pred_2\n        \n        return y_pred","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:40.882961Z","iopub.execute_input":"2023-12-19T19:48:40.884143Z","iopub.status.idle":"2023-12-19T19:48:40.897135Z","shell.execute_reply.started":"2023-12-19T19:48:40.884093Z","shell.execute_reply":"2023-12-19T19:48:40.896016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nRegressorChain is necessary to run 16 parallel XGB models for the lags of our MultiStepTarget. \nHowever,it doesn't seem to work well with EarlyStopping. \nAs a result, the Hybrid model turned out a bid simplistic.\n\"\"\"\nfrom sklearn.multioutput import RegressorChain\n\nmodel_MBH = MultiBoostedHybrid(\n            model_1=LinearRegression(fit_intercept = False),\n            model_2=RegressorChain(\n                XGBRegressor(n_estimators = 10,        #It's an exemplary model. Let it be fast and small \n                             max_depth=3, \n                             learning_rate=0.1, \n                             n_jobs = 8)\n            )\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:40.899144Z","iopub.execute_input":"2023-12-19T19:48:40.899554Z","iopub.status.idle":"2023-12-19T19:48:40.925824Z","shell.execute_reply.started":"2023-12-19T19:48:40.89952Z","shell.execute_reply":"2023-12-19T19:48:40.924741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets reduce the training set down to 2 years\nidxmicro_ = index_[:730]              \nX_vulcano_micro = X_vulcano_cut[X_vulcano_cut.index.isin(idxmicro_)]\ny_train_multi_micro = y_train_multi[y_train_multi.index.isin(idxmicro_)]","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:40.927631Z","iopub.execute_input":"2023-12-19T19:48:40.92813Z","iopub.status.idle":"2023-12-19T19:48:40.981652Z","shell.execute_reply.started":"2023-12-19T19:48:40.928083Z","shell.execute_reply":"2023-12-19T19:48:40.980438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nX_2 is for XGB. It is in 'long' format \n\"\"\"\nX_2 = X_2.unstack(['family', 'store_nbr'])                              # X_2 turns 'wide' first                \nX_2_micro, y_train_multi_micro = X_2.align(y_train_multi_micro,         # then it aligns dates with y, which is in 'long' format\n                                           join='inner', \n                                           axis=0) \nX_2_micro = X_2_micro.stack(['family', 'store_nbr'])                    # and goes back to 'long'    \nX_2_test = X_2_test[['family_fact','onpromotion','store_fact']]         # correct features' order","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:40.998977Z","iopub.execute_input":"2023-12-19T19:48:40.999421Z","iopub.status.idle":"2023-12-19T19:48:42.806922Z","shell.execute_reply.started":"2023-12-19T19:48:40.999388Z","shell.execute_reply":"2023-12-19T19:48:42.805416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_MBH.fit(X_vulcano_micro, X_2_micro, y_train_multi_micro)\n# joblib.dump (model_MBH, 'BoostedHybridMulti.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:42.808601Z","iopub.execute_input":"2023-12-19T19:48:42.809006Z","iopub.status.idle":"2023-12-19T19:48:42.815406Z","shell.execute_reply.started":"2023-12-19T19:48:42.808974Z","shell.execute_reply":"2023-12-19T19:48:42.8138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_MBH = joblib.load('/kaggle/input/timeseriescourse-models/BoostedHybridMulti.pkl')\ny_MBH_fit = pd.DataFrame(model_MBH.predict(X_vulcano_micro, X_2_micro),\n                         index = X_2_micro.index\n                        ).clip(0.0).unstack(['family','store_nbr']) ","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:42.817071Z","iopub.execute_input":"2023-12-19T19:48:42.817668Z","iopub.status.idle":"2023-12-19T19:48:52.635411Z","shell.execute_reply.started":"2023-12-19T19:48:42.817603Z","shell.execute_reply":"2023-12-19T19:48:52.634031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_multistep (y_MBH_fit,\n                START = '2014-01-01', \n                END = '2014-06-15')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:52.637087Z","iopub.execute_input":"2023-12-19T19:48:52.637733Z","iopub.status.idle":"2023-12-19T19:48:56.07367Z","shell.execute_reply.started":"2023-12-19T19:48:52.637693Z","shell.execute_reply":"2023-12-19T19:48:56.072151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_MBH_fore = pd.DataFrame(model_MBH.predict(X_vulcano_test, X_2_test),               \n                        index = X_2_test.index\n                    ).clip(0.0) \ny_MBH_fore = y_MBH_fore.unstack(['family', 'store_nbr'])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:56.075954Z","iopub.execute_input":"2023-12-19T19:48:56.076972Z","iopub.status.idle":"2023-12-19T19:48:57.436617Z","shell.execute_reply.started":"2023-12-19T19:48:56.076918Z","shell.execute_reply":"2023-12-19T19:48:57.435406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_7 = (fetch_forecast(y_MBH_fore)\n                  .join(test.id)\n                  .reset_index(drop=True)\n               )\n\nsubmission_7['sales'] = submission_7.iloc[:,0]\nsubmission_7 = submission_7[['id','sales']]\n# submission_7.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:57.438102Z","iopub.execute_input":"2023-12-19T19:48:57.43851Z","iopub.status.idle":"2023-12-19T19:48:57.589881Z","shell.execute_reply.started":"2023-12-19T19:48:57.438477Z","shell.execute_reply":"2023-12-19T19:48:57.588466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUBMISSION WITH BOOSTED HYBRID, MULTISTEP AND CYCLES\n- Public Score (RMSLE): **0.5607**","metadata":{}},{"cell_type":"markdown","source":"# *A theoretical issue*: **Model's Architecture**\n\nHere comes another subtle point in understanding the nature of the whole process. <br>\nLinReg and XGB are not just two interchangeable options in your pipeline. They are different tools taking different input data in different format at different stages. I've spent days getting my head around it and going many eroneous ways mixing things up, which led me each time to crazy dimentionality, complexity and low metrics.\n\n**LineRegression**\nThe features you give to LinReg are ALL products of your excersises with PeriodIndex: time-dummy, fourier, OHE for specific occasions - all these are made from PeriodIndex.\nYou give it to your LinReg in **wide** format (`unstack()`), where each row corresponds a date: both in X and y. No matter what you want to achieve, you should squeeze it in one row per day. \nYou then fit the LinReg model using X and y, and subsequently, you .predict() with the same X to get y_fit. You subtract y_fit from the original y. Now you have the RESIDUALS that XGB will learn. \n\n**XGBoost**\nAll other features, including products of your excersices with the target (lags, rolling statistics, etc), literally ALL OTHER features - you give them to your XGB as input to learn the RESIDUALS.\nYou provide them to XGB in **long** format using `.stack()`. Why? Because you essentially have as many models as there are columns in 'y'. Running 1782 linear regressions simultaneously (wide format) is one thing, but running 1782 parallel Gradient Boosting Tree models is entirely different. Given your resources, you can afford to run 16 XGB models at once, corresponding to the steps in your forecast (long format). \n\n**Target's shifts and MultiStep target**\nWhen you shift values from the training data, you have data for as many days as your smallest lag. For example, with lag_1, you have data to shift for tomorrow. However, you already lack data for the day after tomorrow because what will be tomorrow is unknown, and there's nothing to shift. If your smallest lag is lag_2, then you have X_test for 2 days, etc.\n\nHowever, given the fact that the shifts should be informed by the *`Autocorrelogram`*, rather then you coding convenince, you have a given set of lags (no matter what you shift there: rolling stats, target values or else).\n\nYour purpose in this case will be to make all the shifted data meet **some shiny day in one row** of your 'wide' table to make **`X_test`** complete. And what do you want the model to give you in exchange for that 1 day data? Exactly! A forecast for the next 16 days.\n\nSo, if picturing it in a 'wide table' format you are passing one row of the data shifted from the training set to get one row of data as a 16 days forecast. And this is why you need to train your model to do that. **This is why you make MultiSteps Target** and teach your model to learn values for 16 days at once. It's all in the sake of that **Big Forecast Day**.\n\n**Last, but not least**. Your picture of a 'wide table' is for you only. When you fetch your X_test, don't forget to .stack() it, because this is how your XGB likes it. \n\n**P.S.** A recurrent re-fitting with 1-step forecasts (direct strategy) is still an option, when using shifts. And it is still bad one.","metadata":{}},{"cell_type":"code","source":"\"\"\"\nI obtained these functions with 'inspect' from the course. You're welcome!\n\"\"\"\n\ndef lagplot(x, y=None, shift=1, standardize=False, ax=None, **kwargs):\n    from matplotlib.offsetbox import AnchoredText                       #\n    x_ = x.shift(shift)\n    if standardize:\n        x_ = (x_ - x_.mean()) / x_.std()\n    if y is not None:\n        y_ = (y - y.mean()) / y.std() if standardize else y\n    else:\n        y_ = x\n    corr = y_.corr(x_)\n    if ax is None:\n        fig, ax = plt.subplots()\n    \n    scatter_kws = dict(\n        alpha=0.75,                            # alpha - transparence\n        s=3,                                   # s - size of the dots\n    )\n    line_kws = dict(color='C3', )              # colore of the line\n    \n    ax = sns.regplot(x=x_,                     # time series x_\n                     y=y_,                     # lagged series y_\n                     scatter_kws=scatter_kws,  \n                     line_kws=line_kws,\n                     lowess=True,              # Locally Weighted Scatterplot Smoothing (makes the line bend to better adjust the relation)\n                     ax=ax,\n                     **kwargs)\n    at = AnchoredText(                         # Annotation with correlation level\n        f\"{corr:.2f}\",\n        prop=dict(size=\"large\"),               # This sets the properties of the text, specifying the font size as \"large.\"\n        frameon=True,                          # frame around the annotation box.\n        loc=\"upper left\",\n    )\n    at.patch.set_boxstyle(\"square, pad=0.0\")   # sets the style of the annotation box (quare with no padding)\n    ax.add_artist(at)                          # This line adds the AnchoredText object (at) to the plot (ax)\n    title = f\"Lag {shift}\" if shift > 0 else f\"Lead {shift}\"\n    ax.set(title=f\"Lag {shift}\", xlabel=x_.name, ylabel=y_.name)\n    return ax\n\ndef plot_lags(x,\n              y=None,\n              lags=6,\n              leads=None,\n              nrows=1,\n              lagplot_kwargs={},\n              **kwargs):\n    import math\n    kwargs.setdefault('nrows', nrows)\n    orig = leads is not None\n    leads = leads or 0\n    kwargs.setdefault('ncols', math.ceil((lags + orig + leads) / nrows))\n    kwargs.setdefault('figsize', (kwargs['ncols'] * 2, nrows * 2 + 0.5))\n    fig, axs = plt.subplots(sharex=True, sharey=True, squeeze=False, **kwargs)\n    for ax, k in zip(fig.get_axes(), range(kwargs['nrows'] * kwargs['ncols'])):\n        k -= leads + orig\n        if k + 1 <= lags:\n            ax = lagplot(x, y, shift=k + 1, ax=ax, **lagplot_kwargs)\n            title = f\"Lag {k + 1}\" if k + 1 >= 0 else f\"Lead {-k - 1}\"\n            ax.set_title(title, fontdict=dict(fontsize=14))\n            ax.set(xlabel=\"\", ylabel=\"\")\n        else:\n            ax.axis('off')\n    plt.setp(axs[-1, :], xlabel=x.name)                               # sets the x-label for the last row of subplots to the name of the x series\n    plt.setp(axs[:, 0], ylabel=y.name if y is not None else x.name)   # sets the y-label for the first column of subplots to the name of the y series (if any)\n    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n    return fig","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:57.59221Z","iopub.execute_input":"2023-12-19T19:48:57.592686Z","iopub.status.idle":"2023-12-19T19:48:57.614047Z","shell.execute_reply.started":"2023-12-19T19:48:57.592648Z","shell.execute_reply":"2023-12-19T19:48:57.612263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nThese plots are based on your selections: family, store, and dates. \nI've experimented with various combinations, and they all yield different results. \nThis suggests there's no relationship between the demand for bikes and frozen pizza across the country. \nThese plots serve more as utility tools here than a visualization of informed decisions.\n\"\"\"\n\nprint (f'Lag plots for {FAMILY} at store {STORE} from {START} till {END}')\n_ = plot_lags(y_true, lags=8, nrows=2)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:48:57.61576Z","iopub.execute_input":"2023-12-19T19:48:57.616097Z","iopub.status.idle":"2023-12-19T19:49:00.097039Z","shell.execute_reply.started":"2023-12-19T19:48:57.616067Z","shell.execute_reply":"2023-12-19T19:49:00.095855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_pacf\nprint (f'Partial Autocorrelation for {FAMILY} at store {STORE} from {START} till {END}')\n_ = plot_pacf(y_true, lags=12)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:00.098674Z","iopub.execute_input":"2023-12-19T19:49:00.099858Z","iopub.status.idle":"2023-12-19T19:49:01.28017Z","shell.execute_reply.started":"2023-12-19T19:49:00.099815Z","shell.execute_reply":"2023-12-19T19:49:01.278734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add three lags for 'sales'\nThe course used three lags, so let's stay consistent with that number.","metadata":{}},{"cell_type":"code","source":"\"\"\"\nFirst, we need to merge 'train' and 'test'. Otherwise, there won't be where to shift lags and leads. \nSimply put, for us to make lag_1, i.e. shift 'sales' value from '2017-08-15' (end of 'train' sample)\nto '2017-08-16' (begin of the 'test' sample), those dates should be in on DataFrame \n\"\"\"\nX_merged = pd.concat([train, test])\nindex_merged = X_merged.index.get_level_values('date').unique()\ny_train_merged = (X_merged\n                 .unstack(['family', 'store_nbr'])\n                 .loc[:,\"sales\"]\n                )","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:01.281846Z","iopub.execute_input":"2023-12-19T19:49:01.282242Z","iopub.status.idle":"2023-12-19T19:49:02.320246Z","shell.execute_reply.started":"2023-12-19T19:49:01.282209Z","shell.execute_reply":"2023-12-19T19:49:02.318886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nAs previously explained, the shifts (lags and leads) should be made per ['family', 'store_nbr'] group.\nX_control is taken to see the picture of accuratelly lagged values (per group)\n'''\n\ndef make_lags(ts, lags, prefix = None):\n    return pd.concat({\n            f'{prefix}_lag_{i}': ts.shift(i)\n            for i in lags\n        },\n        axis=1)\n\nlags = [1,2,3]\nX_lags = (X_merged\n        .groupby(['family', 'store_nbr'])['sales']\n        .apply(make_lags, lags=lags, prefix = 'sales')\n        .fillna(0.0)\n         )\n\n# Check\n# X_control = X_merged.query('family == @FAMILY and store_nbr == @STORE')\n# X_lags.loc[X_control.index]","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:02.321927Z","iopub.execute_input":"2023-12-19T19:49:02.322268Z","iopub.status.idle":"2023-12-19T19:49:23.239385Z","shell.execute_reply.started":"2023-12-19T19:49:02.32224Z","shell.execute_reply":"2023-12-19T19:49:23.237657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nSuch an ideal match may only imply overfitting.\nIn other cicumstances it would be worth a cross-validation check\n'''\ncheck (X_lags, \n       y= y_train, \n       STORE = STORE,\n       model = XGBRegressor(),\n       Prefix = '3 lags')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:23.241178Z","iopub.execute_input":"2023-12-19T19:49:23.2416Z","iopub.status.idle":"2023-12-19T19:49:24.869479Z","shell.execute_reply.started":"2023-12-19T19:49:23.241566Z","shell.execute_reply":"2023-12-19T19:49:24.868533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add three leads for 'onpromotion'","metadata":{}},{"cell_type":"code","source":"def make_leads(ts, leads, prefix = None):\n    return pd.concat({\n            f'{prefix}_lead_{i}': ts.shift(-i)\n            for i in leads\n        },\n        axis=1)\n\n\nleads = [1,2,3]\nX_leads = (X_merged\n           .groupby(['family', 'store_nbr'])['onpromotion']\n           .apply(make_leads, leads=leads, prefix= 'onpromotion')\n           .fillna(0.0)\n          )\n\n# Check\n# X_control = X_merged.query('family == @FAMILY and store_nbr == @STORE')\n# X_leads.loc[X_control.index]","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:24.870664Z","iopub.execute_input":"2023-12-19T19:49:24.871486Z","iopub.status.idle":"2023-12-19T19:49:44.828404Z","shell.execute_reply.started":"2023-12-19T19:49:24.871452Z","shell.execute_reply":"2023-12-19T19:49:44.8271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nTry several options:\n1. Comment 'y = y_promo' to see how this feature works as target predictor\n2. Uncomment 'y = y_promo' to see how y_promo fits the 'onpromotion' ground-truth \n3. Comment 'model = XGBRegressor()' to run the function with LinearRegression() (In case you are in a hurry)\n\"\"\"\n\ny_promo = X_merged.unstack(['family', 'store_nbr']).loc[:,\"onpromotion\"]\n\ncheck(X_leads,\n#       y = y_promo, \n      STORE = STORE,\n      model = XGBRegressor(),\n      Prefix = '3 \"onpromotion\" leads'\n     )","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:44.829863Z","iopub.execute_input":"2023-12-19T19:49:44.83022Z","iopub.status.idle":"2023-12-19T19:49:47.152726Z","shell.execute_reply.started":"2023-12-19T19:49:44.830187Z","shell.execute_reply":"2023-12-19T19:49:47.151544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Assemble and submit","metadata":{}},{"cell_type":"code","source":"X_cycl = pd.concat([X_lags, X_leads], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:47.154515Z","iopub.execute_input":"2023-12-19T19:49:47.154889Z","iopub.status.idle":"2023-12-19T19:49:47.789835Z","shell.execute_reply.started":"2023-12-19T19:49:47.154857Z","shell.execute_reply":"2023-12-19T19:49:47.788552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nThe fit is still perfect. \nXGB must have learned all the noise in the training data.\nSome regularization would be just right.\n\"\"\"\n\ncheck(X_cycl, \n      y = y_train, \n      STORE = STORE,\n      model = XGBRegressor(),\n      Prefix = 'Decycle with 3 \"onpromotion\" leads and 3 \"sales\" lags')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:47.791675Z","iopub.execute_input":"2023-12-19T19:49:47.792698Z","iopub.status.idle":"2023-12-19T19:49:49.503993Z","shell.execute_reply.started":"2023-12-19T19:49:47.792661Z","shell.execute_reply":"2023-12-19T19:49:49.502527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle_family = LabelEncoder()\nX_cycl['family_fact'] = X_cycl.index.get_level_values('family')\nX_cycl['family_fact'] = le_family.fit_transform(X_cycl['family_fact'])\n\nX_cycl['store_fact'] = X_cycl.index.get_level_values('store_nbr').astype(int)\nX_cycl = X_cycl.unstack(['family', 'store_nbr'])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:49.505966Z","iopub.execute_input":"2023-12-19T19:49:49.506793Z","iopub.status.idle":"2023-12-19T19:49:51.476501Z","shell.execute_reply.started":"2023-12-19T19:49:49.506734Z","shell.execute_reply":"2023-12-19T19:49:51.47529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_cycl_train = X_cycl.loc[:'2017-08-15']\nX_cycl_train_micro, y_train_multi_micro = X_cycl_train.align(y_train_multi_micro, join='inner', axis=0)\nX_cycl_train_micro = X_cycl_train_micro.stack(['family', 'store_nbr'])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:51.478336Z","iopub.execute_input":"2023-12-19T19:49:51.478712Z","iopub.status.idle":"2023-12-19T19:49:55.026737Z","shell.execute_reply.started":"2023-12-19T19:49:51.478679Z","shell.execute_reply":"2023-12-19T19:49:55.025309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_cycl_test = X_cycl.loc['2017-08-16':'2017-08-16']\nX_cycl_test = X_cycl_test.stack(['family', 'store_nbr'])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:55.028309Z","iopub.execute_input":"2023-12-19T19:49:55.028705Z","iopub.status.idle":"2023-12-19T19:49:58.090441Z","shell.execute_reply.started":"2023-12-19T19:49:55.028673Z","shell.execute_reply":"2023-12-19T19:49:58.089145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_MBH.fit(X_vulcano_micro, X_cycl_train_micro, y_train_multi_micro)\n# joblib.dump(model_MBH, 'BoostedHybridMultiCycl.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:58.09195Z","iopub.execute_input":"2023-12-19T19:49:58.095727Z","iopub.status.idle":"2023-12-19T19:49:58.101189Z","shell.execute_reply.started":"2023-12-19T19:49:58.095677Z","shell.execute_reply":"2023-12-19T19:49:58.09992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_MBH_cycl = joblib.load('/kaggle/input/timeseriescourse-models/BoostedHybridMultiCycl.pkl')\ny_model_MBH_fit = pd.DataFrame(model_MBH_cycl\n                               .predict(X_vulcano_micro, X_cycl_train_micro),\n                               index = X_cycl_train_micro.index\n                              ).clip(0.0).unstack(['family','store_nbr']) ","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:49:58.104205Z","iopub.execute_input":"2023-12-19T19:49:58.10521Z","iopub.status.idle":"2023-12-19T19:50:08.753094Z","shell.execute_reply.started":"2023-12-19T19:49:58.105164Z","shell.execute_reply":"2023-12-19T19:50:08.751834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_multistep (y_model_MBH_fit,\n                START = '2014-01-01', \n                END = '2014-06-15')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:50:08.755677Z","iopub.execute_input":"2023-12-19T19:50:08.757939Z","iopub.status.idle":"2023-12-19T19:50:12.07942Z","shell.execute_reply.started":"2023-12-19T19:50:08.757868Z","shell.execute_reply":"2023-12-19T19:50:12.078406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_model_MBH_fore = pd.DataFrame(model_MBH_cycl\n                               .predict(X_vulcano_test, X_cycl_test),\n                               index = X_cycl_test.index\n                              ).clip(0.0).unstack(['family','store_nbr'])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:50:12.0806Z","iopub.execute_input":"2023-12-19T19:50:12.081558Z","iopub.status.idle":"2023-12-19T19:50:14.644227Z","shell.execute_reply.started":"2023-12-19T19:50:12.081525Z","shell.execute_reply":"2023-12-19T19:50:14.64283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_8 = (fetch_forecast(y_model_MBH_fore)\n                  .join(test.id)\n                  .reset_index(drop=True)\n               )\n\nsubmission_8['sales'] = submission_8.iloc[:,0]\nsubmission_8 = submission_8[['id','sales']]\n# submission_8.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:50:14.645709Z","iopub.execute_input":"2023-12-19T19:50:14.64616Z","iopub.status.idle":"2023-12-19T19:50:14.796039Z","shell.execute_reply.started":"2023-12-19T19:50:14.646127Z","shell.execute_reply":"2023-12-19T19:50:14.794968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUBMISSION WITH ROLLING STATISTICS\n- Public Score (RMSLE): **0.56976**","metadata":{}},{"cell_type":"markdown","source":"## Rolling_7_mean\nWe've learned how to compute moving averages to estimate trends. Computing **rolling statistics** to be used as features is similar except we need to take care *to avoid lookahead leakage*.<br>\n**First**, the result should be set at the right end of the window instead of the center - that is, we should use `center=False` (the default) in the rolling method. <br>\n**Second**, the target should be lagged a step.","metadata":{}},{"cell_type":"code","source":"\"\"\"\nAbove text is from the course. \nNow you understand that lagging a step is needed to make X_test for the next day after X_train.\nOn your Big Forecast Day of '2017-08-16' you will have rolling statistics up to '2017-08-15',\nwhich will allow you to make a forecast.\n\"\"\"\n\nX_shifted = (X_merged\n            .groupby(['family', 'store_nbr'])[['sales']]\n            .shift(1)\n            .fillna(0.0)\n            .reset_index(level=['family', 'store_nbr'])\n                   )\n\nX_rolling_7_mean = (X_shifted\n                    .groupby(['family', 'store_nbr'])[['sales']]\n                    .rolling(window=7,center=False, min_periods=0)\n                    .mean()\n                    .rename(columns={'sales': '7_days_mean'})\n                    .reset_index()\n                    .set_index(['date', 'family', 'store_nbr'])\n                    )\n\n# X_rolling_7_mean.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T21:17:47.553913Z","iopub.execute_input":"2023-12-19T21:17:47.554558Z","iopub.status.idle":"2023-12-19T21:17:48.937847Z","shell.execute_reply.started":"2023-12-19T21:17:47.554515Z","shell.execute_reply":"2023-12-19T21:17:48.936352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nTry the options:\n1. 'FIT = False' to see two independent curves\n2. 'FIT = True' to see this feature's fit with LinearRegression.\n3. 'FIT = True' and uncomment '#model = XGBRegressor()' to see this feature's fit with XGB. \n    \n    NB: the perfect XGB fit suggests that\n    with a prediction it will be the same: it will perfectly fit to the eroneous \n    forecast produced by another model.\n\"\"\"\ncheck (X_rolling_7_mean, \n       y = y_train, \n       STORE = STORE, \n       FIT = False, \n       model = XGBRegressor(),\n       Prefix = f'Rolling_7_mean')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:38:44.456049Z","iopub.execute_input":"2023-12-19T20:38:44.456597Z","iopub.status.idle":"2023-12-19T20:38:46.024604Z","shell.execute_reply.started":"2023-12-19T20:38:44.456561Z","shell.execute_reply":"2023-12-19T20:38:46.023127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Rolling_7_std","metadata":{}},{"cell_type":"code","source":"X_rolling_7_std = (X_shifted\n                    .groupby(['family', 'store_nbr'])[['sales']]\n                    .rolling (window = 7,center = False,min_periods = 0)\n                    .std()\n                    .fillna(0.0)\n                    .rename(columns={'sales':'7_days_std'})\n                    .reset_index()\n                    .set_index(['date', 'family', 'store_nbr'])\n                    )\n# X_rolling_7_std.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:49:11.165917Z","iopub.execute_input":"2023-12-19T20:49:11.166437Z","iopub.status.idle":"2023-12-19T20:49:12.369261Z","shell.execute_reply.started":"2023-12-19T20:49:11.166396Z","shell.execute_reply":"2023-12-19T20:49:12.36741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nTry the options:\n1. 'FIT = False' to see two independent curves\n2. 'FIT = True' to see this feature's fit with LinearRegression.\n3. 'FIT = True' and uncomment '#model = XGBRegressor()' to see this feature's fit with XGB. \n\"\"\"\ncheck (X_rolling_7_std, \n       y = y_train, \n       STORE = STORE, \n#        FIT = False,\n       model = XGBRegressor(),\n       Prefix = f'rolling_7_std')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:40:26.735961Z","iopub.execute_input":"2023-12-19T20:40:26.736388Z","iopub.status.idle":"2023-12-19T20:40:28.233918Z","shell.execute_reply.started":"2023-12-19T20:40:26.736357Z","shell.execute_reply":"2023-12-19T20:40:28.232215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Rolling_5_exp","metadata":{}},{"cell_type":"code","source":"X_rolling_5_exp = (X_shifted\n                    .groupby(['family', 'store_nbr'])[['sales']]\n                    .ewm (span = 5,\n                          adjust= False)\n                    .mean()\n                    .rename(columns={'sales':'5_days_exp'})\n                    .reset_index()\n                    .set_index(['date', 'family', 'store_nbr'])\n                    )\n\n# X_rolling_5_exp.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:50:52.826073Z","iopub.execute_input":"2023-12-19T20:50:52.826654Z","iopub.status.idle":"2023-12-19T20:50:53.870592Z","shell.execute_reply.started":"2023-12-19T20:50:52.826615Z","shell.execute_reply":"2023-12-19T20:50:53.869098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nTry the options:\n1. 'FIT = False' to see two independent curves\n2. 'FIT = True' to see this feature's fit with LinearRegression.\n3. 'FIT = True' and uncomment '#model = XGBRegressor()' to see this feature's fit with XGB. \n\"\"\"\ncheck (X_rolling_5_exp, \n       y = y_train, \n       STORE = STORE, \n       FIT = False,\n       model = XGBRegressor(),\n       Prefix = f'rolling_5_exp')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:51:01.095774Z","iopub.execute_input":"2023-12-19T20:51:01.096303Z","iopub.status.idle":"2023-12-19T20:51:02.560204Z","shell.execute_reply.started":"2023-12-19T20:51:01.096236Z","shell.execute_reply":"2023-12-19T20:51:02.558607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Assemble and submit","metadata":{}},{"cell_type":"code","source":"X_cycl_ = X_cycl.stack(['family', 'store_nbr'])\nX_rolling = pd.concat([\n                X_cycl_,\n                X_rolling_7_mean,\n                X_rolling_7_std,\n                X_rolling_5_exp\n            ],\n                axis = 1\n)\n\nX_rolling = X_rolling.unstack(['family', 'store_nbr'])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:59:57.036504Z","iopub.execute_input":"2023-12-19T20:59:57.04008Z","iopub.status.idle":"2023-12-19T21:06:54.095837Z","shell.execute_reply.started":"2023-12-19T20:59:57.039962Z","shell.execute_reply":"2023-12-19T21:06:54.094295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_rolling_train = X_rolling.loc[:'2017-08-15']\nX_rolling_train_micro, y_train_multi_micro = X_rolling_train.align(y_train_multi_micro, join='inner', axis=0)\nX_rolling_train_micro = X_rolling_train_micro.stack(['family', 'store_nbr'])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T21:07:10.366004Z","iopub.execute_input":"2023-12-19T21:07:10.366601Z","iopub.status.idle":"2023-12-19T21:07:16.342784Z","shell.execute_reply.started":"2023-12-19T21:07:10.366559Z","shell.execute_reply":"2023-12-19T21:07:16.341238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_rolling_test = X_rolling.loc['2017-08-16':'2017-08-16']\nX_rolling_test = X_rolling_test.stack(['family', 'store_nbr'])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T21:07:16.345633Z","iopub.execute_input":"2023-12-19T21:07:16.346789Z","iopub.status.idle":"2023-12-19T21:07:21.634493Z","shell.execute_reply.started":"2023-12-19T21:07:16.346704Z","shell.execute_reply":"2023-12-19T21:07:21.632446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_MBH.fit(X_vulcano_micro, X_rolling_train_micro, y_train_multi_micro)\n# joblib.dump(model_MBH, 'BoostedHybridMultiCyclRoll.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T21:07:23.755993Z","iopub.execute_input":"2023-12-19T21:07:23.757063Z","iopub.status.idle":"2023-12-19T21:10:32.181149Z","shell.execute_reply.started":"2023-12-19T21:07:23.75701Z","shell.execute_reply":"2023-12-19T21:10:32.179751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_MBH_roll = joblib.load('/kaggle/input/timeseriescourse-models/BoostedHybridMultiCyclRoll.pkl')\ny_rolling_fit = pd.DataFrame(model_MBH_roll\n                               .predict(X_vulcano_micro, X_rolling_train_micro),\n                               index = X_rolling_train_micro.index\n                              ).clip(0.0).unstack(['family','store_nbr']) ","metadata":{"execution":{"iopub.status.busy":"2023-12-19T21:13:19.681507Z","iopub.execute_input":"2023-12-19T21:13:19.682208Z","iopub.status.idle":"2023-12-19T21:15:10.348975Z","shell.execute_reply.started":"2023-12-19T21:13:19.682153Z","shell.execute_reply":"2023-12-19T21:15:10.347253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_multistep (y_rolling_fit,\n                START = '2014-01-01', \n                END = '2014-06-15'\n                )","metadata":{"execution":{"iopub.status.busy":"2023-12-19T21:15:10.352106Z","iopub.execute_input":"2023-12-19T21:15:10.352561Z","iopub.status.idle":"2023-12-19T21:15:13.424346Z","shell.execute_reply.started":"2023-12-19T21:15:10.352523Z","shell.execute_reply":"2023-12-19T21:15:13.423084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_rolling_fore = pd.DataFrame(model_MBH_roll\n                               .predict(X_vulcano_test, X_rolling_test),\n                               index = X_cycl_test.index\n                              ).clip(0.0).unstack(['family','store_nbr'])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T21:15:25.337998Z","iopub.execute_input":"2023-12-19T21:15:25.33854Z","iopub.status.idle":"2023-12-19T21:15:27.816109Z","shell.execute_reply.started":"2023-12-19T21:15:25.338499Z","shell.execute_reply":"2023-12-19T21:15:27.814177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_9 = (fetch_forecast(y_rolling_fore)\n                  .join(test.id)\n                  .reset_index(drop=True)\n               )\n\nsubmission_9['sales'] = submission_9.iloc[:,0]\nsubmission_9 = submission_9[['id','sales']]\n# submission_9.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T21:15:27.818974Z","iopub.execute_input":"2023-12-19T21:15:27.819681Z","iopub.status.idle":"2023-12-19T21:15:28.096321Z","shell.execute_reply.started":"2023-12-19T21:15:27.819456Z","shell.execute_reply":"2023-12-19T21:15:28.094435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bonus: *Simple submission from the course*\nPublic Score (RMSLE): **0.63832**","metadata":{}},{"cell_type":"code","source":"X, X_test = dp.in_sample(), dp.out_of_sample(16) \nX['NewYearsDay'] = (X.index.dayofyear == 1) * 1.0\nX_test['NewYearsDay'] = (X_test.index.dayofyear == 1) * 1.0\n\nX_2 = X_2.stack(['family','store_nbr'])\nX_2 = X_2[['onpromotion','family_fact','store_fact']]\nX_2_test = X_2_test[['onpromotion','family_fact','store_fact']]","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:50:54.553401Z","iopub.execute_input":"2023-12-19T19:50:54.5538Z","iopub.status.idle":"2023-12-19T19:50:55.5869Z","shell.execute_reply.started":"2023-12-19T19:50:54.553766Z","shell.execute_reply":"2023-12-19T19:50:55.585676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"course_model = BoostedHybrid(\n                model_1=LinearRegression(fit_intercept = False),\n                model_2=XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)\n    )","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:50:55.588477Z","iopub.execute_input":"2023-12-19T19:50:55.588855Z","iopub.status.idle":"2023-12-19T19:50:55.595013Z","shell.execute_reply.started":"2023-12-19T19:50:55.588821Z","shell.execute_reply":"2023-12-19T19:50:55.593709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# course_model.fit (X, X_2, y_train)\n# joblib.dump(course_model, 'course_model.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:50:55.597029Z","iopub.execute_input":"2023-12-19T19:50:55.598038Z","iopub.status.idle":"2023-12-19T19:50:55.608388Z","shell.execute_reply.started":"2023-12-19T19:50:55.598001Z","shell.execute_reply":"2023-12-19T19:50:55.607153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"course_model = joblib.load('/kaggle/input/timeseriescourse-models/course_model.pkl')\ny_course = course_model.predict(X_test, X_2_test).clip(0.0)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:50:55.609687Z","iopub.execute_input":"2023-12-19T19:50:55.61002Z","iopub.status.idle":"2023-12-19T19:50:56.39484Z","shell.execute_reply.started":"2023-12-19T19:50:55.609992Z","shell.execute_reply":"2023-12-19T19:50:56.393711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_10 = (y_course\n            .to_frame()\n            .reset_index()\n            .rename(columns = {'level_0':'date'})\n            .set_index(['date','family', 'store_nbr'])\n            .sort_index()    \n            .join(test.id)\n            .rename(columns = {0:'sales'})\n            .reset_index(drop=True)\n            .reindex(columns = ['id','sales'])\n            )\n\n# submission_10.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T19:50:56.396549Z","iopub.execute_input":"2023-12-19T19:50:56.397216Z","iopub.status.idle":"2023-12-19T19:50:56.429549Z","shell.execute_reply.started":"2023-12-19T19:50:56.39718Z","shell.execute_reply":"2023-12-19T19:50:56.428339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Credits**:\n- [Rayn Holbrook](https://www.kaggle.com/ryanholbrook) for his brilliant [Time Series course](https://www.kaggle.com/learn/time-series)\n- 🐋 whales of the Pacific (feels like a good chance to appreciate them)\n\nIf you liked this notebook, please also check the others:\n - [🗺️Geospatial Analysis Course: Practical Guide](https://www.kaggle.com/ivanlydkin/geospatial-analysis-course-practical-guide)\n - [🤖Computer Vision course: Practical Guide](https://www.kaggle.com/code/ivanlydkin/computer-vision-course-practical-guide)\n - [🛳️Original feature for Titanic](https://www.kaggle.com/code/ivanlydkin/titanic-case-with-some-original-features)\n\n*I hope it was helpful* 🤝<br>\n<blockquote style=\"margin-right:auto; margin-left:auto; background-color: #faf0be; padding: 1em; margin:24px;\">\n<strong> Please upvote if you find this valuable, and don't hesitate to leave comments if you have any feedback or suggestions</strong> </blockquote><br> ","metadata":{}}]}